<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.12" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.46" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://springg.us.kg/posts/BigData/08_Spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85.html"><meta property="og:site_name" content="mrjason’s Blog"><meta property="og:title" content="Spark环境的安装"><meta property="og:description" content="Spark环境的安装 一、 Spark简介 1.1 Spark是什么 是一种基于内存的快速、通用、可拓展的大数据分析计算引擎。 1.2 Hadoop 和 Spark关联 hadoop ：2013年10月发布2.X (Yarn)版本； spark ： 2013年6月，Spark成为了Apache基金会下的项目。 Spark可以理解为hadoop MR的升..."><meta property="og:type" content="article"><meta property="og:image" content="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602020855.png"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2024-10-28T01:58:08.000Z"><meta property="article:author" content="MrJason"><meta property="article:modified_time" content="2024-10-28T01:58:08.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Spark环境的安装","image":["https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602020855.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602021032.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602021626.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602021747.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602022304.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602022554.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602181641.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602185736.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602192241.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602192318.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602192716.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602193202.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602195125.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602195414.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602205820.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602211114.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602211320.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602215038.jpg","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602215334.png","https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200602215352.png"],"dateModified":"2024-10-28T01:58:08.000Z","author":[{"@type":"Person","name":"MrJason","url":"https://springg.us.kg"}]}</script><meta name="referrer" content="no-referrer-when-downgrade"><link rel="icon" href="/favicon.ico"><link rel="icon" href="/assets/icon/chrome-mask-512.png" type="image/png" sizes="512x512"><link rel="icon" href="/assets/icon/chrome-mask-192.png" type="image/png" sizes="192x192"><link rel="icon" href="/assets/icon/chrome-512.png" type="image/png" sizes="512x512"><link rel="icon" href="/assets/icon/chrome-192.png" type="image/png" sizes="192x192"><link rel="manifest" href="/manifest.webmanifest" crossorigin="use-credentials"><meta name="theme-color" content="#46bd87"><link rel="apple-touch-icon" href="/assets/icon/apple-icon-152.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="msapplication-TileImage" content="/assets/icon/ms-icon-144.png"><meta name="msapplication-TileColor" content="#ffffff"><link rel="alternate" type="application/rss+xml" href="https://springg.us.kg/rss.xml" title="mrjason’s Blog RSS Feed"><title>Spark环境的安装 | mrjason’s Blog</title><meta name="description" content="Spark环境的安装 一、 Spark简介 1.1 Spark是什么 是一种基于内存的快速、通用、可拓展的大数据分析计算引擎。 1.2 Hadoop 和 Spark关联 hadoop ：2013年10月发布2.X (Yarn)版本； spark ： 2013年6月，Spark成为了Apache基金会下的项目。 Spark可以理解为hadoop MR的升...">
    <link rel="preload" href="/assets/style-7mm7FOTp.css" as="style"><link rel="stylesheet" href="/assets/style-7mm7FOTp.css">
    <link rel="modulepreload" href="/assets/app-4x2aIoqi.js"><link rel="modulepreload" href="/assets/1.Spark环境的安装.html-DeGvMBfD.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">mrjason’s Blog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><span class="font-icon icon iconfont icon-home" style=""></span><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/demo/" aria-label="导航"><!--[--><span class="font-icon icon iconfont icon-discover" style=""></span><!--]-->导航<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="笔记分类"><!--[--><span class="font-icon icon iconfont icon-edit" style=""></span>笔记分类<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">代码笔记</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Computer-Basics/" aria-label="计算机基础"><!--[--><span class="font-icon icon iconfont icon-windows" style=""></span><!--]-->计算机基础<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Data-Structure/" aria-label="数据结构与算法"><!--[--><span class="font-icon icon iconfont icon-calculate" style=""></span><!--]-->数据结构与算法<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Web/" aria-label="前端笔记"><!--[--><span class="font-icon icon iconfont icon-code" style=""></span><!--]-->前端笔记<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Linux/" aria-label="Linux"><!--[--><span class="font-icon icon iconfont icon-linux" style=""></span><!--]-->Linux<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Python/" aria-label="Python"><!--[--><span class="font-icon icon iconfont icon-python" style=""></span><!--]-->Python<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Database/" aria-label="数据库"><!--[--><span class="font-icon icon iconfont icon-table" style=""></span><!--]-->数据库<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Docker/" aria-label="Docker"><!--[--><span class="font-icon icon iconfont icon-expansion" style=""></span><!--]-->Docker<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Git/" aria-label="Git"><!--[--><span class="font-icon icon iconfont icon-git" style=""></span><!--]-->Git<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Redis/" aria-label="Redis"><!--[--><span class="font-icon icon iconfont icon-lock" style=""></span><!--]-->Redis<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/MiddleWare/" aria-label="中间件"><!--[--><span class="font-icon icon iconfont icon-process" style=""></span><!--]-->中间件<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/posts/BigData/" aria-label="大数据"><!--[--><span class="font-icon icon iconfont icon-hot" style=""></span><!--]-->大数据<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Architect/" aria-label="架构师"><!--[--><span class="font-icon icon iconfont icon-study" style=""></span><!--]-->架构师<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Daily-Thoughts/" aria-label="日常思考"><!--[--><span class="font-icon icon iconfont icon-mark" style=""></span><!--]-->日常思考<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/Development-Tools/" aria-label="开发工具"><!--[--><span class="font-icon icon iconfont icon-tool" style=""></span><!--]-->开发工具<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">博客相关</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/blog/" aria-label="博客相关"><!--[--><span class="font-icon icon iconfont icon-blog" style=""></span><!--]-->博客相关<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/posts/Java/" aria-label="Java"><!--[--><span class="font-icon icon iconfont icon-java" style=""></span><!--]-->Java<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/collect.html" aria-label="收藏"><!--[--><span class="font-icon icon iconfont icon-hk-shoucang1" style=""></span><!--]-->收藏<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/news/" aria-label="说说"><!--[--><span class="font-icon icon iconfont icon-news" style=""></span><!--]-->说说<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/visitorsbook.html" aria-label="留言板"><!--[--><span class="font-icon icon iconfont icon-mark" style=""></span><!--]-->留言板<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/friend.html" aria-label="友链"><!--[--><span class="font-icon icon iconfont icon-link" style=""></span><!--]-->友链<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="关于"><!--[--><span class="font-icon icon iconfont icon-info" style=""></span>关于<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/intro.html" aria-label="关于我"><!--[--><span class="font-icon icon iconfont icon-people" style=""></span><!--]-->关于我<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/about.html" aria-label="关于本站"><!--[--><span class="font-icon icon iconfont icon-info" style=""></span><!--]-->关于本站<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://foreverblog.cn/go.html" title="穿梭虫洞-随机访问十年之约友链博客" target="_blank" rel="noopener noreferrer" aria-label="wormhole"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="currentColor" style="width:1.25rem;height:1.25rem;vertical-align:middle"><path d="M644.608 665.6c192.512-171.008 342.016-395.776 254.464-494.592-27.648-31.232-66.56-45.568-108.032-41.472-34.816 3.584-70.656 20.992-107.008 50.176-116.224-59.904-254.464-55.296-366.592 11.776-86.016 51.2-148.48 134.656-172.544 231.936-18.944 74.24-14.336 152.064 12.8 223.744-44.544 50.688-86.528 154.624-34.816 212.992 21.504 24.576 52.736 35.328 90.112 35.328 114.176-0.512 286.72-100.864 431.616-229.888z m155.648-452.608c14.848-1.536 26.624 2.56 36.352 13.824 9.728 10.752 7.168 39.936-10.752 80.896-18.944-28.672-41.984-55.296-68.096-77.824 17.92-10.752 32.256-15.872 42.496-16.896z m-598.528 517.12c18.944 27.136 40.96 51.712 66.048 73.216-43.008 12.8-72.192 11.776-81.92 1.024-8.704-10.752 0.512-45.056 15.872-74.24z m685.568-246.784c-51.2 75.264-122.368 154.112-200.704 224.256-81.408 72.192-171.008 134.656-254.464 176.64 26.112 5.632 52.224 8.704 78.848 8.704 68.096 0 135.168-18.944 194.048-53.76 124.416-73.216 195.072-211.968 182.272-355.84z m0 0" p-id="4157"></path></svg></a></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://www.travellings.cn/go.html" title="开往" target="_blank" rel="noopener noreferrer" aria-label="travelling"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="currentColor" style="width:1.25rem;height:1.25rem;vertical-align:middle"><path d="M658.836 519.32c-22.121 0-40.145 18.431-40.145 40.957 0 22.528 18.023 40.962 40.145 40.962 22.117 0 40.141-18.434 40.141-40.962 0-22.526-18.024-40.957-40.141-40.957zM364.742 519.32c-22.121 0-40.141 18.431-40.141 40.957 0.41 22.528 18.02 40.962 40.141 40.962 22.117 0 40.141-18.434 40.141-40.962 0-22.526-18.024-40.957-40.141-40.957z" p-id="8700"></path><path d="M512 0C229.23 0 0 229.23 0 512s229.23 512 512 512 512-229.23 512-512S794.77 0 512 0z m133.727 804.81c0 7.375-6.145 13.52-13.516 13.52H391.773c-7.371 0-13.515-6.145-13.515-13.52v-13.516c0-7.371 6.144-13.517 13.515-13.517h240.438c7.371 0 13.516 6.146 13.516 13.517v13.516z m120.832 37.273c-12.289 6.965-27.441 2.867-34.406-9.418l-54.887-96.668c-4.504 0.82-9.422 1.23-13.926 1.23H361.054c-4.914 0-9.421-0.41-13.925-1.23l-54.887 96.668c-6.965 12.285-22.527 16.383-34.406 9.418-12.289-6.961-16.383-22.938-9.422-35.223l51.199-90.113c-27.031-19.66-43.418-52.43-40.957-88.883l19.25-293.273c3.277-49.152 34.406-88.066 87.246-88.066h80.281c0-37.684 29.899-67.993 66.762-67.993 36.868 0 66.766 30.309 66.766 67.993h93.391c53.246 0 70.449 38.914 73.727 88.066l19.25 293.273c2.461 36.453-13.926 69.223-40.957 88.883l51.199 90.113c6.964 12.696 2.867 28.262-9.012 35.223z" p-id="8701"></path><path d="M672.352 314.931H351.633c-14.747 0-26.622 12.285-26.622 27.441v108.953c0 15.157 11.875 27.446 26.622 27.446h320.719c14.746 0 26.625-12.289 26.625-27.446V342.372c0-15.156-11.879-27.441-26.625-27.441z" p-id="8702"></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/" aria-label="01 大数据生态圈"><!---->01 大数据生态圈<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">02 Hive总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">04 Flume总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">04 接入层</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">05 Zookeeper总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">05 数据处理层</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">06 Kafka总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">07 Scala总结</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">08 Spark</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/5.Spark%E4%B9%8BWordCount.html" aria-label="Spark 之 WordCount"><!---->Spark 之 WordCount<!----></a></li><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/6.SparkSQL.html" aria-label="SparkSQL"><!---->SparkSQL<!----></a></li><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/7.SparkStreaming.html" aria-label="SparkStreaming"><!---->SparkStreaming<!----></a></li><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/8.Spark%E5%86%85%E6%A0%B8.html" aria-label="Spark内核"><!---->Spark内核<!----></a></li><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/4.%20Spark%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%94%B5%E5%95%86%E6%8C%87%E6%A0%87%E7%BB%9F%E8%AE%A1.html" aria-label="Spark实战项目——电商指标统计"><!---->Spark实战项目——电商指标统计<!----></a></li><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/2.Spark%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%BC%96%E7%A8%8B.html" aria-label="Spark架构及编程"><!---->Spark架构及编程<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link vp-sidebar-page active" href="/posts/BigData/08_Spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85.html" aria-label="Spark环境的安装"><!---->Spark环境的安装<!----></a></li><li><a class="route-link auto-link vp-sidebar-link vp-sidebar-page" href="/posts/BigData/08_Spark/3.Spark%E7%BC%96%E7%A8%8B2.html" aria-label="Spark编程2"><!---->Spark编程2<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">10 Hbase</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">11 数仓</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Spark环境的安装</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://springg.us.kg" target="_blank" rel="noopener noreferrer">MrJason</a></span><span property="author" content="MrJason"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-10-28T01:58:08.000Z"></span><span class="page-pageview-info" aria-label="访问量🔢" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon eye-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="eye icon" name="eye"><path d="M992 512.096c0-5.76-.992-10.592-1.28-11.136-.192-2.88-1.152-8.064-2.08-10.816-.256-.672-.544-1.376-.832-2.08-.48-1.568-1.024-3.104-1.6-4.32C897.664 290.112 707.104 160 512 160c-195.072 0-385.632 130.016-473.76 322.592-1.056 2.112-1.792 4.096-2.272 5.856a55.512 55.512 0 00-.64 1.6c-1.76 5.088-1.792 8.64-1.632 7.744-.832 3.744-1.568 11.168-1.568 11.168-.224 2.272-.224 4.032.032 6.304 0 0 .736 6.464 1.088 7.808.128 1.824.576 4.512 1.12 6.976h-.032c.448 2.08 1.12 4.096 1.984 6.08.48 1.536.992 2.976 1.472 4.032C126.432 733.856 316.992 864 512 864c195.136 0 385.696-130.048 473.216-321.696 1.376-2.496 2.24-4.832 2.848-6.912.256-.608.48-1.184.672-1.728 1.536-4.48 1.856-8.32 1.728-8.32l-.032.032c.608-3.104 1.568-7.744 1.568-13.28zM512 672c-88.224 0-160-71.776-160-160s71.776-160 160-160 160 71.776 160 160-71.776 160-160 160z"></path></svg><span id="ArtalkPV" class="vp-pageview waline-pageview-count" data-path="/posts/BigData/08_Spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85.html" data-page-key="/posts/BigData/08_Spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85.html">...</span></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 14 分钟</span><meta property="timeRequired" content="PT14M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#一、-spark简介">一、 Spark简介</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-spark是什么">1.1 Spark是什么</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-hadoop-和-spark关联">1.2 Hadoop 和 Spark关联</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-3-spark的核心框架">1.3 Spark的核心框架</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#二、spark快速上手">二、Spark快速上手</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#创建maven工程">创建Maven工程</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-增加scala插件">2.1 增加Scala插件</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-增加依赖关系">2.2  增加依赖关系</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-3-增加日志文件配置文件">2.3  增加日志文件配置文件</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-4-wordcount">2.4   WordCount</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#三、-spark运行环境">三、 Spark运行环境</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-1-spark的运行环境">3.1 Spark的运行环境</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-2-本地运行模式">3.2 本地运行模式</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-3-独立运行模式">3.3 独立运行模式</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-4-yarn">3.4 YARN</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-5-k8s-mesos模式">3.5 K8S &amp; Mesos模式</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-6-windows-模式">3.6 Windows 模式</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-7-部署模式的对比">3.7 部署模式的对比</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-8-端口号">3.8 端口号</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><h1 id="spark环境的安装" tabindex="-1"><a class="header-anchor" href="#spark环境的安装"><span>Spark环境的安装</span></a></h1><hr><h2 id="一、-spark简介" tabindex="-1"><a class="header-anchor" href="#一、-spark简介"><span>一、 Spark简介</span></a></h2><h3 id="_1-1-spark是什么" tabindex="-1"><a class="header-anchor" href="#_1-1-spark是什么"><span>1.1 Spark是什么</span></a></h3><blockquote><p>是一种基于<strong>内存</strong>的快速、通用、可拓展的大数据<strong>分析计算引擎</strong>。</p></blockquote><h3 id="_1-2-hadoop-和-spark关联" tabindex="-1"><a class="header-anchor" href="#_1-2-hadoop-和-spark关联"><span>1.2 Hadoop 和 Spark关联</span></a></h3><blockquote><ol><li>hadoop ：2013年10月发布2.X (Yarn)版本；</li><li>spark ： 2013年6月，Spark成为了Apache基金会下的项目。</li><li>Spark可以理解为hadoop MR的升级版。</li></ol></blockquote><h4 id="_1-2-1-hadoop发展历史" tabindex="-1"><a class="header-anchor" href="#_1-2-1-hadoop发展历史"><span>1.2.1 hadoop发展历史</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 1.X 版本 --2011年发布</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">从架构的角度存在很多的问题</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. Namenode 是单点操作，所以容易出现单点故障，制约了HDFS的发展</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. Namenode的内存限制也影响了HDFS的发展</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. MapReduce是一种基于数据集的工作模式，面向数据，这种工作模式一般是从存储上加载数据集，然后操作数据集，最后将结果写入物理存储设备。数据更多面临的是一次性计算，所以初衷是单一数据计算，不支持迭代计算</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. 资源调度和任务调度耦合在一起，无法扩展，</span><span style="color:#D19A66;--shiki-dark:#D19A66;">所以Hadoop1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">X版本只支持MR计算框架</span></span></code></pre></div><p>![image-20200602020855518](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602020855.png)</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 2.X 版本（Yarn） --2013.10月发布</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.X版本支持Namenode高可用</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.X版本使用新的资源调度框架Yarn，只做资源调度，不进行任务调度。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. MR框架只做任务调度，可插拔，所以扩展性非常的强</span></span></code></pre></div><p>![image-20200602021032775](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602021032.png)</p><h4 id="_1-2-2-spark-技术" tabindex="-1"><a class="header-anchor" href="#_1-2-2-spark-技术"><span>1.2.2 Spark 技术</span></a></h4><blockquote><ol><li><p>Spark其实核心思想就是基于MR的，优化了MR数据处理的中间过程，提升了数据处理的性能</p></li><li><p>MR：多任务之间的数据会进行落盘</p></li><li><p>Spark：多任务之间的数据会在内存中。</p></li><li><p>因为内存大小也有上限的，当内存不足时，就会出现job运行失败，所以Spark并不是完全替代MR。</p></li></ol></blockquote><ul><li>MR和Spark区别</li></ul><p>![image-20200602021626723](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602021626.png)</p><p>![image-20200602021747457](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602021747.png)</p><ul><li>Spark的特点</li></ul><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. spark计算模型更加丰富，MR只有mapper和reducer， spark的计算模型模糊了mapper和reduce的界限，更容易使用;</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. spark使用scala语言开发，支持函数式编程，所以就更利用迭代式计算.</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. spark也有自己的任务调度器和资源调度器。</span></span></code></pre></div><p>![image-20200602022304372](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602022304.png)</p><h4 id="_1-2-3-spark-on-yarn" tabindex="-1"><a class="header-anchor" href="#_1-2-3-spark-on-yarn"><span>1.2.3 Spark On Yarn</span></a></h4><blockquote><p>在实际开发中，hadoop和Spark合二为一。</p><p>调度器：Hadoop的Yarn</p><p>任务执行：Spark的任务调度，Driver和Executor</p></blockquote><p>![image-20200602022554760](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602022554.png)</p><h3 id="_1-3-spark的核心框架" tabindex="-1"><a class="header-anchor" href="#_1-3-spark的核心框架"><span>1.3 Spark的核心框架</span></a></h3><p>![image-20200602181641619](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602181641.png)</p><blockquote><ol><li>Apache Spark Core : 最基础和最核心的功能</li><li>Spark SQL :用于处理关系型数据库</li><li>Spark Streaming：针对实时数据的处理流式计算的框架，Flink框架更有优势</li><li>Spark MLlib: 机器学习</li><li>Spark Graphx:面向图形计算</li></ol></blockquote><p>我们重点学习Spark前面三个框架。</p><h2 id="二、spark快速上手" tabindex="-1"><a class="header-anchor" href="#二、spark快速上手"><span>二、Spark快速上手</span></a></h2><h3 id="创建maven工程" tabindex="-1"><a class="header-anchor" href="#创建maven工程"><span>创建Maven工程</span></a></h3><h3 id="_2-1-增加scala插件" tabindex="-1"><a class="header-anchor" href="#_2-1-增加scala插件"><span>2.1 增加Scala插件</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--当前使用的Spark版本为2.4.5，默认采用的Scala版本为2.12</span></span></code></pre></div><h3 id="_2-2-增加依赖关系" tabindex="-1"><a class="header-anchor" href="#_2-2-增加依赖关系"><span>2.2 增加依赖关系</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--修改Maven项目中的POM文件，增加Spark框架的依赖关系。当前文件是基于Spark2.4.5版本，使用时请注意对应版本</span></span></code></pre></div><div class="language-xml line-numbers-mode" data-ext="xml" data-title="xml"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">dependencies</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">dependency</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">groupId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;org.apache.spark&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">groupId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">artifactId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;spark-core_2.12&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">artifactId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">version</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;2.4.5&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">version</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">dependency</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">dependencies</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">build</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">plugins</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        &lt;!-- 该插件用于将Scala代码编译成class文件 --&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">plugin</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">groupId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;net.alchim31.maven&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">groupId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">artifactId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;scala-maven-plugin&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">artifactId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">version</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;3.2.2&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">version</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">executions</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">execution</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                    &lt;!-- 声明绑定到maven的compile阶段 --&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goals</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goal</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;testCompile&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goal</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goals</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">execution</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">executions</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">plugin</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">plugin</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">groupId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;org.apache.maven.plugins&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">groupId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">artifactId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;maven-assembly-plugin&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">artifactId</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">version</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;3.0.0&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">version</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">configuration</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">descriptorRefs</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">descriptorRef</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;jar-with-dependencies&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">descriptorRef</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">descriptorRefs</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">configuration</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">executions</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">execution</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">id</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;make-assembly&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">id</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">phase</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;package&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">phase</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goals</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                        &lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goal</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;single&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goal</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">goals</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">execution</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">executions</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">plugin</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    &lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">plugins</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">build</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-3-增加日志文件配置文件" tabindex="-1"><a class="header-anchor" href="#_2-3-增加日志文件配置文件"><span>2.3 增加日志文件配置文件</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 在项目的resources目录中创建log4j.properties文件，并将如下信息添加到文件中（日志信息）：</span></span></code></pre></div><div class="language-properties line-numbers-mode" data-ext="properties" data-title="properties"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.rootCategory</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR, console</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.appender.console</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">org.apache.log4j.ConsoleAppender</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.appender.console.target</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">System.err</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.appender.console.layout</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">org.apache.log4j.PatternLayout</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.appender.console.layout.ConversionPattern</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Set the default spark-shell log level to ERROR. When running the spark-shell, the</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># log level for this class is used to overwrite the root logger&#39;s log level, so that</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># the user can have different defaults for the shell and regular Spark apps.</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.org.apache.spark.repl.Main</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Settings to quiet third party logs that are too verbose</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.org.spark_project.jetty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">log4j.logger.org.apache.spark.repl.SparkIMain$</span><span style="color:#C678DD;--shiki-dark:#C678DD;">exprTyper</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">log4j.logger.org.apache.spark.repl.SparkILoop$</span><span style="color:#C678DD;--shiki-dark:#C678DD;">SparkILoopInterpreter</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.org.apache.parquet</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.parquet</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">FATAL</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">ERROR</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-4-wordcount" tabindex="-1"><a class="header-anchor" href="#_2-4-wordcount"><span>2.4 WordCount</span></a></h3><ul><li>方法1：</li></ul><div class="language-scala" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">步骤：</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//1. 创建Spark的环境</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//2. 连接Spark</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//3. 具体的操作</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//4. 关闭连接</span></span></code></pre></div><div class="language-scala line-numbers-mode" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">object</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> Spark_WordCount</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">  def</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> main</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">args</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Array</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">]): </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Unit</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //需求：读取一个文件中的数据，求(word,count)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //1. 创建Spark的环境</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> sparkConf</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">SparkConf</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> SparkConf</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">().setMaster(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;local&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">).setAppName(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;wordcount&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //2. 连接Spark</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> sc</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> SparkContext</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(sparkConf)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3. 具体的操作</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3.1 读取数据</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> str</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> sc.textFile(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;input&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3.2 扁平化数据</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> words</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> str.flatMap(_.split(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot; &quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3.3 分组</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> wordtocount</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Iterable</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">])] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> words.groupBy(word </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> word)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3.4 结构化处理</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> wordcount</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Int</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> wordtocount.map {</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">      case</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (word, iter) </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (word, iter.size)</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    }</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3.5 数据采集并打印在控制台</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> result</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Array</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Int</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> wordcount.collect()</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    println(result.mkString(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;,&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //4. 关闭连接</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    sc.stop()</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">  }</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>方法二</li></ul><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 在方法1的基础上，将分组和结构化处理操作进行优化。</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 方法1：//3.3 分组 +  //3.4 结构化处理</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">分组操作结果：(spark , List(spark,spark)) </span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">结构化处理结果：(spark,</span><span style="color:#D19A66;--shiki-dark:#D19A66;">list</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">length</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 优化方法：在进行分组操作的同时就进行单词出现的次数进行计算。</span></span></code></pre></div><div class="language-scala line-numbers-mode" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">object</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> Spark_WordCount1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">  def</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> main</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">args</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Array</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">]): </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Unit</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //1. 创建spark的环境</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> sparkConf</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">SparkConf</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> SparkConf</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">().setMaster(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;local&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">).setAppName(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;wordcount&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //2. 与spark进行连接</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> sc</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> SparkContext</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(sparkConf)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //3. 具体的操作</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> datas</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> sc.textFile(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;input&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> words</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> datas.flatMap(_.split(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot; &quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> wordto</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Int</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> words.map((_,</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    val</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> wordcount</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RDD</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Int</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)] </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> wordto.reduceByKey(_ </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> _)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    println(wordcount.collect().mkString(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;,&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    //4. 关闭连接</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    sc.stop()</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">  }</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="三、-spark运行环境" tabindex="-1"><a class="header-anchor" href="#三、-spark运行环境"><span>三、 Spark运行环境</span></a></h2><h3 id="_3-1-spark的运行环境" tabindex="-1"><a class="header-anchor" href="#_3-1-spark的运行环境"><span>3.1 Spark的运行环境</span></a></h3><p>![image-20200602185736933](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602185736.png)</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">我们主要学习3种环境，并简单讲述一下2种环境</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">学习的环境：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. 本地运行模式：</span><span style="color:#C678DD;--shiki-dark:#C678DD;">local</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. 独立运行模式：standalone</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. YARN运行模式</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">简单了解：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. MESOS</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Windows</span></span></code></pre></div><h3 id="_3-2-本地运行模式" tabindex="-1"><a class="header-anchor" href="#_3-2-本地运行模式"><span>3.2 本地运行模式</span></a></h3><h4 id="_3-2-1-本地模式介绍" tabindex="-1"><a class="header-anchor" href="#_3-2-1-本地模式介绍"><span>3.2.1 本地模式介绍</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 1. 什么是本地模式</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> 不需要其他任何节点资源就可以在本地执行Spark代码的环境.</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> 我们之前在IDEA中运行的环境我们称之为开发环境，和本地环境还是不一样</span></span></code></pre></div><h4 id="_3-2-2-解压缩文件" tabindex="-1"><a class="header-anchor" href="#_3-2-2-解压缩文件"><span>3.2.2 解压缩文件</span></a></h4><ul><li>第一步：解压缩</li></ul><ol><li>将spark-2.4.5-bin-without-hadoop-scala-2.12.tgz文件上传到Linux中/opt/software，并解压缩到/opt/module文件目录下，并修改名称为：spark-local</li></ol><div class="language-scala" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//解压</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">tar </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">zxvf spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.4.5</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">without</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">scala</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.tgz </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">C</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> /</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">opt</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">/</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">module</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//改名</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">mv spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.4.5</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">without</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">scala</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">local</span></span></code></pre></div><ul><li>第二步：Spark关联hadoop，spark2.4.5默认不支持Hadoop3，可以采用多种不同的方式关联Hadoop3</li></ul><ol><li>方法1：修改spark-local/conf/spark-env.sh文件，增加如下内容</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">SPARK_DIST_CLASSPATH</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$(/opt/module/hadoop3/bin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">hadoop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> classpath)</span></span></code></pre></div><ol start="2"><li>方法2：将hadoop3的jar包上传到==/opt/module/spark-local/jars==</li></ol><h4 id="_3-2-3-启动local环境" tabindex="-1"><a class="header-anchor" href="#_3-2-3-启动local环境"><span>3.2.3 启动local环境</span></a></h4><ol><li>进入/opt/module/spark-local路径，执行如下指令</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-local]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ bin/spark-shell </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master local</span></span></code></pre></div><p>![image-20200602192241228](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602192241.png)</p><ol start="2"><li>启动成功后，可以输入网址进行Web UI监控页面访问</li></ol><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>http://hadoop105:4040</span></span></code></pre></div><p>![image-20200602192318112](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602192318.png)</p><p>3.2.4 命令行工具</p><ol><li>在==<strong>/opt/module/spark-local/data</strong>==目录下创建一个文件：word.txt，在文件中随机写入一些单词</li><li>在==<strong>/opt/module/spark-local</strong>==下，执行如下命令</li></ol><div class="language-scala" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[atguigu@hadoop105 spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">local]$ sc.textFile(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;data/word.txt&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">).flatMap(_.split(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot; &quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)).map((_,</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)).reduceByKey(_</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">_).collect</span></span></code></pre></div><p>![image-20200602192716232](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602192716.png)</p><h4 id="_3-2-4-退出本地模式" tabindex="-1"><a class="header-anchor" href="#_3-2-4-退出本地模式"><span>3.2.4 退出本地模式</span></a></h4><ul><li>按键Ctrl+C或输入Scala指令</li></ul><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>：quit</span></span></code></pre></div><h4 id="_3-2-5-提交应用" tabindex="-1"><a class="header-anchor" href="#_3-2-5-提交应用"><span>3.2.5 提交应用</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-local]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ bin/spark-submit \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class org.apache.spark.examples.SparkPi \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master local[2] \</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">./examples/jars/spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar \</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span></span></code></pre></div><ul><li>参数说明</li></ul><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">spark-submit ： 提交应用程序</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class 表示要执行程序的主类</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master local[2] ： 本地部署模式，local，本地，[2],数字2表示分配的cpu核数</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar ： 执行程序的主类所在的jar包</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ： 用于设定当前应用的任务数量</span></span></code></pre></div><p>![image-20200602193202267](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602193202.png)</p><h3 id="_3-3-独立运行模式" tabindex="-1"><a class="header-anchor" href="#_3-3-独立运行模式"><span>3.3 独立运行模式</span></a></h3><h4 id="_3-3-1-独立运行介绍" tabindex="-1"><a class="header-anchor" href="#_3-3-1-独立运行介绍"><span>3.3.1 独立运行介绍</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 什么是独立运行模式</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">   1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. standalone，表示资源调度器和任务调度均是使用Sqark自身的集群来运行。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">      a、资源调度：</span><span style="color:#C678DD;--shiki-dark:#C678DD;">master</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(Spark的调度者),worker(Spark节点)</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">      b、任务调度：driver(驱动器)，exerutor(执行器)</span></span></code></pre></div><h4 id="_3-3-2-解压缩文件" tabindex="-1"><a class="header-anchor" href="#_3-3-2-解压缩文件"><span>3.3.2 解压缩文件</span></a></h4><ul><li>第一步：解压缩</li></ul><ol><li>将spark-2.4.5-bin-without-hadoop-scala-2.12.tgz文件上传到Linux中/opt/software，并解压缩到/opt/module文件目录下，并修改名称为：spark-standalone</li></ol><div class="language-scala" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//解压</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">tar </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">zxvf spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.4.5</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">without</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">scala</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.tgz </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">C</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> /</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">opt</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">/</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">module</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//改名</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">mv spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.4.5</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">without</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">scala</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">standalone</span></span></code></pre></div><ul><li>第二步：Spark关联hadoop，spark2.4.5默认不支持Hadoop3，可以采用多种不同的方式关联Hadoop3</li></ul><ol><li>方法1：修改spark-local/conf/spark-env.sh文件，增加如下内容</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">SPARK_DIST_CLASSPATH</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$(/opt/module/hadoop3/bin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">hadoop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> classpath)</span></span></code></pre></div><ol start="2"><li>方法2：将hadoop3的jar包上传到==/opt/module/spark-local/jars==</li></ol><h4 id="_3-3-3-修改配置文件" tabindex="-1"><a class="header-anchor" href="#_3-3-3-修改配置文件"><span>3.3.3 修改配置文件</span></a></h4><ol><li>进入/opt/module/spark-standalone/conf，修改slaves.template文件名为slaves</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ mv </span><span style="color:#D19A66;--shiki-dark:#D19A66;">slaves</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">template</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> slaves</span></span></code></pre></div><ol start="2"><li>修改slaves文件，添加work节点</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop105</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop106</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop107</span></span></code></pre></div><ol start="3"><li><a href="http://xn--spark-env-z89nz78p.sh.xn--templatespark-env-rn60ab6huy0bm27f.sh" target="_blank" rel="noopener noreferrer">修改spark-env.sh.template文件名为spark-env.sh</a></li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ mv spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">env</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.template spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">env</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="4"><li>修改spark-env.sh文件，添加JAVA_HOME环境变量和集群对应的master节点</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export JAVA_HOME</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/opt/module/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">jdk1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.0_212</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">SPARK_MASTER_HOST</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop105</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">SPARK_MASTER_PORT</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">7077</span></span></code></pre></div><blockquote><p>注意：7077端口，相当于hadoop3内部通信的8020端口</p></blockquote><ol start="5"><li>分发spark-standalone目录</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">xsync spark-standalone</span></span></code></pre></div><h4 id="_3-3-4-启动集群" tabindex="-1"><a class="header-anchor" href="#_3-3-4-启动集群"><span>3.3.4 启动集群</span></a></h4><ol><li>执行脚本命令：</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 打开集群,先启动Master，再启动worker</span></span>
<span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">all</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 关闭集群,先关闭worker，再关闭Master</span></span>
<span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">stop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">all</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="2"><li>查看三台服务器的进程</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ myjps</span></span></code></pre></div><p>![image-20200602195125350](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602195125.png)</p><ol start="3"><li>查看Master的资源监控Web UI 网页界面：<a href="http://hadoop105:8080" target="_blank" rel="noopener noreferrer">http://hadoop105:8080</a></li></ol><p>![image-20200602195414292](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602195414.png)</p><h4 id="_3-3-5-提交应用" tabindex="-1"><a class="header-anchor" href="#_3-3-5-提交应用"><span>3.3.5 提交应用</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$bin/spark-submit \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class org.apache.spark.examples.SparkPi \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master spark://hadoop105:7077 \</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">./examples/jars/spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar \</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span></span></code></pre></div><ul><li>参数说明</li></ul><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">spark-submit  </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 提交应用</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class       -- 表示要执行程序的主类</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master spark://hadoop105:7077 -- 独立运行模式，7070为spark内部通信的端口</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar   </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 程序主类所在的jar</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  -- 设定当前应用的任务数量</span></span></code></pre></div><h4 id="_3-3-6-提交参数说明" tabindex="-1"><a class="header-anchor" href="#_3-3-6-提交参数说明"><span>3.3.6 提交参数说明</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin/spark-submit \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class &lt;main-class&gt;</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master &lt;master-url&gt; \</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">... # other options</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#C678DD;--shiki-dark:#C678DD;">application</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-jar</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> \</span></span>
<span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[application-arguments]</span></span></code></pre></div><table><thead><tr><th>参数</th><th>解释[可选值举例 ]</th></tr></thead><tbody><tr><td>--class</td><td>Spark程序中包含主函数的类</td></tr><tr><td>--master</td><td>Spark程序运行的模式 <strong>[本地模式：local[*]、spark://linux1:7077、Yarn ]</strong></td></tr><tr><td>--executor-memory 1G</td><td>指定每个executor可用内存为1G <strong>[符合集群内存配置即可，具体情况具体分析 ]</strong></td></tr><tr><td>--total-executor-cores 2</td><td>指定所有executor使用的cpu核数为2个</td></tr><tr><td>--executor-cores</td><td>指定每个executor使用的cpu核数</td></tr><tr><td>application-jar</td><td>打包好的应用jar，包含依赖。这个URL在集群中全局可见。 比如hdfs:// 共享存储系统，如果是file:// path，那么所有的节点的path都包含同样的jar</td></tr><tr><td>application-arguments</td><td>传给main()方法的参数</td></tr></tbody></table><h4 id="_3-3-7-配置历史服务器" tabindex="-1"><a class="header-anchor" href="#_3-3-7-配置历史服务器"><span>3.3.7 配置历史服务器</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 由于spark-shell停止掉后，集群监控hadoop105:4040页面就看不到历史任务的运行情况，所以开发时都配置历史服务器记录任务运行情况</span></span></code></pre></div><ol><li>修改spark-defaults.conf.template文件名为spark-defaults.conf</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ mv spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">defaults</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">conf</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.template spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">defaults</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">conf</span></span></code></pre></div><ol start="2"><li>修改spark-default.conf文件，配置日志存储路径</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">spark</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eventLog</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">enabled</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">          true</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">spark</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eventLog</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.dir               hdfs://hadoop105:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8020</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/directory</span></span></code></pre></div><blockquote><p>注意：需要启动hadoop集群，HDFS上的directory目录需要提前存在</p></blockquote><ol start="3"><li>修改spark-env.sh文件, 添加日志配置</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export SPARK_HISTORY_OPTS</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.history.ui.port=18080 </span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.history.fs.logDirectory=hdfs://hadoop105:8020/directory </span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.history.retainedApplications=30&quot;</span></span></code></pre></div><ul><li><p>参数1含义：WEBUI访问的端口号为18080</p></li><li><p>参数2含义：指定历史服务器日志存储路径</p></li><li><p>参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</p></li></ul><ol start="4"><li>分发配置文件</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">xsync conf</span></span></code></pre></div><ol start="5"><li>重新启动集群和历史服务</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">all</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-history-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="6"><li>重新执行任务</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$bin/spark-submit \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class org.apache.spark.examples.SparkPi \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master spark://hadoop105:7077 \</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">./examples/jars/spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar \</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span></span></code></pre></div><ol start="7"><li>查看历史服务：<a href="http://hadoop105:18080" target="_blank" rel="noopener noreferrer">http://hadoop105:18080</a></li></ol><p>![image-20200602205819323](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602205820.png)</p><h4 id="_3-3-8-配置高可用" tabindex="-1"><a class="header-anchor" href="#_3-3-8-配置高可用"><span>3.3.8 配置高可用</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 因为Spark集群中的Master只有一个，存在单点故障，所以需要给集群配置多个Master，一旦处于活跃的Master故障时，StandBy的Master转换为活跃的，提供服务。</span></span></code></pre></div><ul><li>集群规划</li></ul><table><thead><tr><th style="text-align:center;"></th><th style="text-align:center;">Hadoop105</th><th style="text-align:center;">Hadoop106</th><th style="text-align:center;">Hadoop107</th></tr></thead><tbody><tr><td style="text-align:center;">Spark</td><td style="text-align:center;">MasterZookeeperWorker</td><td style="text-align:center;">MasterZookeeperWorker</td><td style="text-align:center;">ZookeeperWorker</td></tr></tbody></table><ol><li>停止集群</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">stop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">all</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="2"><li>启动Zookeeper</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ zk </span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span></span></code></pre></div><ol start="3"><li>修改spark-env.sh文件添加如下配置</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">#注释如下内容：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">#SPARK_MASTER_HOST</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">linux1</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">#SPARK_MASTER_PORT</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">7077</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">SPARK_MASTER_WEBUI_PORT</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8989</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">#添加如下内容:</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export SPARK_DAEMON_JAVA_OPTS</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.deploy.recoveryMode=ZOOKEEPER </span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.deploy.zookeeper.url=hadoop105,hadoop106,hadoop107 </span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.deploy.zookeeper.dir=/spark&quot;</span></span></code></pre></div><ol start="4"><li>分发配置文件</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ xsync conf/</span></span></code></pre></div><ol start="5"><li>启动集群</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">all</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="6"><li>启动lhadoop106的单独Master节点，此时hadoop106节点Master状态处于备用状态</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop106 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">master</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><p>![image-20200602211112909](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602211114.png)</p><ol start="7"><li>停止hadoop105的Master资源监控进程</li><li>查看hadoop106的Master 资源监控Web UI，稍等一段时间后，hadoop106节点的Master状态提升为活动状态</li></ol><p>![image-20200602211320022](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602211320.png)</p><h3 id="_3-4-yarn" tabindex="-1"><a class="header-anchor" href="#_3-4-yarn"><span>3.4 YARN</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. Spark重点在与实时的计算引擎，而不是资源框架，所以本身提供资源调度并不是其本身。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. 所以参考在YARN环境下运行Spark。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. 资源调度：hadoop的yarn</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">   执行任务： spark的driver和executor</span></span></code></pre></div><h4 id="_3-4-1-解压缩文件" tabindex="-1"><a class="header-anchor" href="#_3-4-1-解压缩文件"><span>3.4.1 解压缩文件</span></a></h4><ul><li>第一步：解压缩</li></ul><ol><li>将spark-2.4.5-bin-without-hadoop-scala-2.12.tgz文件上传到Linux中/opt/software，并解压缩到/opt/module文件目录下，并修改名称为：spark-yarn</li></ol><div class="language-scala" data-ext="scala" data-title="scala"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//解压</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">tar </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">zxvf spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.4.5</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">without</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">scala</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.tgz </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">C</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> /</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">opt</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">/</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">module</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//改名</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">mv spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.4.5</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">bin</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">without</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">scala</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2.12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> spark</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">-</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">yarn</span></span></code></pre></div><ul><li>第二步：Spark关联hadoop，spark2.4.5默认不支持Hadoop3，可以采用多种不同的方式关联Hadoop3</li></ul><ol><li>方法1：修改spark-local/conf/spark-env.sh文件，增加如下内容</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">SPARK_DIST_CLASSPATH</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$(/opt/module/hadoop3/bin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">hadoop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> classpath)</span></span></code></pre></div><ol start="2"><li>方法2：将hadoop3的jar包上传到==/opt/module/spark-local/jars==</li></ol><h4 id="_3-4-2-修改配置文件" tabindex="-1"><a class="header-anchor" href="#_3-4-2-修改配置文件"><span>3.4.2 修改配置文件</span></a></h4><ol><li>修改hadoop配置文件/opt/module/hadoop/etc/hadoop/yarn-site.xml, <mark>并分发</mark></li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">!</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">property</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">     &lt;</span><span style="color:#C678DD;--shiki-dark:#C678DD;">name</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#D19A66;--shiki-dark:#D19A66;">yarn</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">nodemanager</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.pmem-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">check</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">enabled</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">name</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">     &lt;</span><span style="color:#C678DD;--shiki-dark:#C678DD;">value</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">false</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">value</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/property</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">!</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">property</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">     &lt;</span><span style="color:#C678DD;--shiki-dark:#C678DD;">name</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#D19A66;--shiki-dark:#D19A66;">yarn</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">nodemanager</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.vmem-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">check</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">enabled</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">name</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">     &lt;</span><span style="color:#C678DD;--shiki-dark:#C678DD;">value</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">false</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">value</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/property</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span></code></pre></div><ol start="2"><li>修改conf/spark-env.sh，添加JAVA_HOME和YARN_CONF_DIR配置</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 改名</span></span>
<span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ mv spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">env</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.template spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">env</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 添加配置</span></span>
<span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ vim spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">env</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export JAVA_HOME</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/opt/module/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">jdk1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.0_212</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">YARN_CONF_DIR</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/opt/module/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">hadoop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/etc/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">hadoop</span></span></code></pre></div><h4 id="_3-4-3-启动hadoop集群" tabindex="-1"><a class="header-anchor" href="#_3-4-3-启动hadoop集群"><span>3.4.3 启动hadoop集群</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ mycluster </span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span></span></code></pre></div><h4 id="_3-4-4-提交应用" tabindex="-1"><a class="header-anchor" href="#_3-4-4-提交应用"><span>3.4.4 提交应用</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$bin/spark-submit \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class org.apache.spark.examples.SparkPi \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master spark://hadoop105:7077 \</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">./examples/jars/spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar \</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span></span></code></pre></div><p>查看http://hadoop105:8088页面，点击History，查看历史页面</p><h4 id="_3-4-5-配置历史服务器" tabindex="-1"><a class="header-anchor" href="#_3-4-5-配置历史服务器"><span>3.4.5 配置历史服务器</span></a></h4><ol><li>修改spark-defaults.conf.template文件名为spark-defaults.conf</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 conf]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ mv spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">defaults</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">conf</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.template spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">defaults</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">conf</span></span></code></pre></div><ol start="2"><li>修改spark-default.conf文件，配置日志存储路径</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">spark</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eventLog</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">enabled</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">          true</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">spark</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eventLog</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.dir               hdfs://hadoop105:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8020</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/directory</span></span></code></pre></div><blockquote><p>注意：需要启动hadoop集群，HDFS上的directory目录需要提前存在</p></blockquote><ol start="3"><li>修改spark-env.sh文件, 添加日志配置</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export SPARK_HISTORY_OPTS</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.history.ui.port=18080 </span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.history.fs.logDirectory=hdfs://hadoop105:8020/directory </span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">-Dspark.history.retainedApplications=30&quot;</span></span></code></pre></div><ul><li><p>参数1含义：WEBUI访问的端口号为18080</p></li><li><p>参数2含义：指定历史服务器日志存储路径</p></li><li><p>参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</p></li></ul><ol start="4"><li>修改spark-defaults.conf</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">spark</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">yarn</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">historyServer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">address</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop105:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">18080</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">spark</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">history</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">ui</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">port</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">18080</span></span></code></pre></div><ol start="5"><li>启动历史服务</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">sbin/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-history-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="6"><li>重新提交应用</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop105 spark-standalone]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$bin/spark-submit \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--class org.apache.spark.examples.SparkPi \</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--master spark://hadoop105:7077 \</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">./examples/jars/spark-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">examples_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.jar \</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span></span></code></pre></div><p>![img](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602215038.jpg)</p><ol start="7"><li>Web页面查看日志：<a href="http://hadoop106:8088" target="_blank" rel="noopener noreferrer">http://hadoop106:8088</a></li></ol><h3 id="_3-5-k8s-mesos模式" tabindex="-1"><a class="header-anchor" href="#_3-5-k8s-mesos模式"><span>3.5 K8S &amp; Mesos模式</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">Mesos是Apache下的开源分布式资源管理框架，它被称为是分布式系统的内核,在Twitter得到广泛使用,管理着Twitter超过30,0000台服务器上的应用部署，但是在国内，依然使用着传统的Hadoop大数据框架，所以国内使用Mesos框架的并不多，但是原理其实都差不多，这里我们就不做过多讲解了。</span></span></code></pre></div><p>![image-20200602215334165](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602215334.png)</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">容器化部署是目前业界很流行的一项技术，基于Docker镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是Kubernetes（k8s），而Spark也在最近的版本中支持了k8s部署模式</span></span></code></pre></div><p>![image-20200602215352244](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200602215352.png)</p><h3 id="_3-6-windows-模式" tabindex="-1"><a class="header-anchor" href="#_3-6-windows-模式"><span>3.6 Windows 模式</span></a></h3><ol><li>将文件spark-2.4.5-bin-without-hadoop-scala-2.12.tgz解压缩到无中文无空格的路径中，将hadoop3依赖jar包拷贝到jars目录中</li><li>执行解压缩文件路径下bin目录中的spark-shell.cmd文件，启动Spark本地环境</li><li>在bin目录中创建input目录，并添加word.txt文件, 在命令行中输入脚本代码</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">sc</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">textFile</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;input&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">).flatMap(</span><span style="color:#D19A66;--shiki-dark:#D19A66;">_</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">split</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot; &quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)).map((_,</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)).reduceByKey(_+_).collect</span></span></code></pre></div><h3 id="_3-7-部署模式的对比" tabindex="-1"><a class="header-anchor" href="#_3-7-部署模式的对比"><span>3.7 部署模式的对比</span></a></h3><table><thead><tr><th style="text-align:center;">模式</th><th style="text-align:center;">Spark安装机器数</th><th style="text-align:center;">需启动的进程</th><th style="text-align:center;">所属者</th><th style="text-align:center;">应用场景</th></tr></thead><tbody><tr><td style="text-align:center;">Local</td><td style="text-align:center;">1</td><td style="text-align:center;">无</td><td style="text-align:center;">Spark</td><td style="text-align:center;">测试</td></tr><tr><td style="text-align:center;">Standalone</td><td style="text-align:center;">3</td><td style="text-align:center;">Master及Worker</td><td style="text-align:center;">Spark</td><td style="text-align:center;">单独部署</td></tr><tr><td style="text-align:center;">Yarn</td><td style="text-align:center;">1</td><td style="text-align:center;">Yarn及HDFS</td><td style="text-align:center;">Hadoop</td><td style="text-align:center;">混合部署</td></tr></tbody></table><h3 id="_3-8-端口号" tabindex="-1"><a class="header-anchor" href="#_3-8-端口号"><span>3.8 端口号</span></a></h3><table><thead><tr><th>端口</th><th>作用</th></tr></thead><tbody><tr><td>8080</td><td>资源的监控页面端口</td></tr><tr><td>7077</td><td>Spark的worker内部通信的端口</td></tr><tr><td>4040</td><td>计算的监控页面端口</td></tr><tr><td>18080</td><td>历史服务器端口</td></tr><tr><td>8088</td><td>RM的资源监控端口</td></tr></tbody></table></div><!--[--><div class="sponsor" data-v-cd22ff44><div id="drinks-box" data-v-cd22ff44><div id="drinks-box-s" class="drinks-button left-100" data-v-cd22ff44><div id="drinks-icons" class="left-100 tr3" data-v-cd22ff44><div id="coffee-donate" class="icon-donate" data-v-cd22ff44><span class="font-icon icon iconfont icon-hk-flutter" data-v-cd22ff44></span> 赞助 </div></div><div id="drinks-button-box" class="tr3 left-100" data-v-cd22ff44><div id="drinks-button-bg" class="left-100" data-v-cd22ff44></div><ul id="donate-buttons" class="list tr3" data-v-cd22ff44><li id="person_donate" class="donate-button" data-v-cd22ff44>个人码</li><li id="alipay_donate" class="donate-button1" data-v-cd22ff44>AliPay</li><li id="wechat_donate" class="donate-button2" data-v-cd22ff44>WeChat</li></ul></div><div id="drinks-qrcodes" class="left-100 tr3" data-v-cd22ff44><div id="drinks-qrcode" data-v-cd22ff44></div></div></div></div></div><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/MrjackC/mrjackc.github.io/edit/main/src/posts/BigData/08_Spark/1.Spark环境的安装.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><!----></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 845886914@qq.com">MrJason</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/BigData/08_Spark/2.Spark%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%BC%96%E7%A8%8B.html" aria-label="Spark架构及编程"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->Spark架构及编程</div></a><a class="route-link auto-link next" href="/posts/BigData/08_Spark/3.Spark%E7%BC%96%E7%A8%8B2.html" aria-label="Spark编程2"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">Spark编程2<!----></div></a></nav><div id="vp-comment" class="waline-wrapper" darkmode="false" style="display:block;"><div data-waline provider="Waline"><div class="wl-reaction"><div class="wl-reaction-title">你认为这篇文章怎么样？</div><ul class="wl-reaction-list"><!--[--><li class="wl-reaction-item"><div class="wl-reaction-img"><img src="//unpkg.com/@waline/emojis/tieba/tieba_agree.png"><div class="wl-reaction-votes">0</div></div><div class="wl-reaction-text"></div></li><li class="wl-reaction-item"><div class="wl-reaction-img"><img src="//unpkg.com/@waline/emojis/tieba/tieba_look_down.png"><div class="wl-reaction-votes">0</div></div><div class="wl-reaction-text"></div></li><li class="wl-reaction-item"><div class="wl-reaction-img"><img src="//unpkg.com/@waline/emojis/tieba/tieba_sunglasses.png"><div class="wl-reaction-votes">0</div></div><div class="wl-reaction-text"></div></li><li class="wl-reaction-item"><div class="wl-reaction-img"><img src="//unpkg.com/@waline/emojis/tieba/tieba_pick_nose.png"><div class="wl-reaction-votes">0</div></div><div class="wl-reaction-text"></div></li><li class="wl-reaction-item"><div class="wl-reaction-img"><img src="//unpkg.com/@waline/emojis/tieba/tieba_awkward.png"><div class="wl-reaction-votes">0</div></div><div class="wl-reaction-text"></div></li><li class="wl-reaction-item"><div class="wl-reaction-img"><img src="//unpkg.com/@waline/emojis/tieba/tieba_sleep.png"><div class="wl-reaction-votes">0</div></div><div class="wl-reaction-text"></div></li><!--]--></ul></div><div class="wl-comment"><!--v-if--><div class="wl-panel"><div class="wl-header item3"><!--[--><div class="wl-header-item"><label for="wl-nick">昵称</label><input id="wl-nick" class="wl-input wl-nick" name="nick" type="text" value></div><div class="wl-header-item"><label for="wl-mail">邮箱</label><input id="wl-mail" class="wl-input wl-mail" name="mail" type="email" value></div><div class="wl-header-item"><label for="wl-link">网址(可选)</label><input id="wl-link" class="wl-input wl-link" name="link" type="text" value></div><!--]--></div><textarea id="wl-edit" class="wl-editor" placeholder="请留言。(填写邮箱可在被回复时收到邮件提醒)"></textarea><div class="wl-preview" style="display:none;"><hr><h4>预览:</h4><div class="wl-content"></div></div><div class="wl-footer"><div class="wl-actions"><a href="https://guides.github.com/features/mastering-markdown/" title="Markdown Guide" aria-label="Markdown is supported" class="wl-action" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" ariaHidden="true"><path d="M14.85 3H1.15C.52 3 0 3.52 0 4.15v7.69C0 12.48.52 13 1.15 13h13.69c.64 0 1.15-.52 1.15-1.15v-7.7C16 3.52 15.48 3 14.85 3zM9 11H7V8L5.5 9.92 4 8v3H2V5h2l1.5 2L7 5h2v6zm2.99.5L9.5 8H11V5h2v3h1.5l-2.51 3.5z" fill="currentColor"></path></svg></a><button type="button" class="wl-action" title="表情" style="display:none;"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M563.2 463.3 677 540c1.7 1.2 3.7 1.8 5.8 1.8.7 0 1.4-.1 2-.2 2.7-.5 5.1-2.1 6.6-4.4l25.3-37.8c1.5-2.3 2.1-5.1 1.6-7.8s-2.1-5.1-4.4-6.6l-73.6-49.1 73.6-49.1c2.3-1.5 3.9-3.9 4.4-6.6.5-2.7 0-5.5-1.6-7.8l-25.3-37.8a10.1 10.1 0 0 0-6.6-4.4c-.7-.1-1.3-.2-2-.2-2.1 0-4.1.6-5.8 1.8l-113.8 76.6c-9.2 6.2-14.7 16.4-14.7 27.5.1 11 5.5 21.3 14.7 27.4zM387 348.8h-45.5c-5.7 0-10.4 4.7-10.4 10.4v153.3c0 5.7 4.7 10.4 10.4 10.4H387c5.7 0 10.4-4.7 10.4-10.4V359.2c0-5.7-4.7-10.4-10.4-10.4zm333.8 241.3-41-20a10.3 10.3 0 0 0-8.1-.5c-2.6.9-4.8 2.9-5.9 5.4-30.1 64.9-93.1 109.1-164.4 115.2-5.7.5-9.9 5.5-9.5 11.2l3.9 45.5c.5 5.3 5 9.5 10.3 9.5h.9c94.8-8 178.5-66.5 218.6-152.7 2.4-5 .3-11.2-4.8-13.6zm186-186.1c-11.9-42-30.5-81.4-55.2-117.1-24.1-34.9-53.5-65.6-87.5-91.2-33.9-25.6-71.5-45.5-111.6-59.2-41.2-14-84.1-21.1-127.8-21.1h-1.2c-75.4 0-148.8 21.4-212.5 61.7-63.7 40.3-114.3 97.6-146.5 165.8-32.2 68.1-44.3 143.6-35.1 218.4 9.3 74.8 39.4 145 87.3 203.3.1.2.3.3.4.5l36.2 38.4c1.1 1.2 2.5 2.1 3.9 2.6 73.3 66.7 168.2 103.5 267.5 103.5 73.3 0 145.2-20.3 207.7-58.7 37.3-22.9 70.3-51.5 98.1-85 27.1-32.7 48.7-69.5 64.2-109.1 15.5-39.7 24.4-81.3 26.6-123.8 2.4-43.6-2.5-87-14.5-129zm-60.5 181.1c-8.3 37-22.8 72-43 104-19.7 31.1-44.3 58.6-73.1 81.7-28.8 23.1-61 41-95.7 53.4-35.6 12.7-72.9 19.1-110.9 19.1-82.6 0-161.7-30.6-222.8-86.2l-34.1-35.8c-23.9-29.3-42.4-62.2-55.1-97.7-12.4-34.7-18.8-71-19.2-107.9-.4-36.9 5.4-73.3 17.1-108.2 12-35.8 30-69.2 53.4-99.1 31.7-40.4 71.1-72 117.2-94.1 44.5-21.3 94-32.6 143.4-32.6 49.3 0 97 10.8 141.8 32 34.3 16.3 65.3 38.1 92 64.8 26.1 26 47.5 56 63.6 89.2 16.2 33.2 26.6 68.5 31 105.1 4.6 37.5 2.7 75.3-5.6 112.3z" fill="currentColor"></path></svg></button><button type="button" class="wl-action" title="表情包"><svg width="24" height="24" fill="currentcolor" viewBox="0 0 24 24"><path style="transform: translateY(0.5px)" d="M18.968 10.5H15.968V11.484H17.984V12.984H15.968V15H14.468V9H18.968V10.5V10.5ZM8.984 9C9.26533 9 9.49967 9.09367 9.687 9.281C9.87433 9.46833 9.968 9.70267 9.968 9.984V10.5H6.499V13.5H8.468V12H9.968V14.016C9.968 14.2973 9.87433 14.5317 9.687 14.719C9.49967 14.9063 9.26533 15 8.984 15H5.984C5.70267 15 5.46833 14.9063 5.281 14.719C5.09367 14.5317 5 14.2973 5 14.016V9.985C5 9.70367 5.09367 9.46933 5.281 9.282C5.46833 9.09467 5.70267 9.001 5.984 9.001H8.984V9ZM11.468 9H12.968V15H11.468V9V9Z"></path><path d="M18.5 3H5.75C3.6875 3 2 4.6875 2 6.75V18C2 20.0625 3.6875 21.75 5.75 21.75H18.5C20.5625 21.75 22.25 20.0625 22.25 18V6.75C22.25 4.6875 20.5625 3 18.5 3ZM20.75 18C20.75 19.2375 19.7375 20.25 18.5 20.25H5.75C4.5125 20.25 3.5 19.2375 3.5 18V6.75C3.5 5.5125 4.5125 4.5 5.75 4.5H18.5C19.7375 4.5 20.75 5.5125 20.75 6.75V18Z"></path></svg></button><input id="wl-image-upload" class="upload" aria-hidden="true" type="file" accept=".png,.jpg,.jpeg,.webp,.bmp,.gif"><label for="wl-image-upload" class="wl-action" title="上传图片" aria-label="上传图片"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M784 112H240c-88 0-160 72-160 160v480c0 88 72 160 160 160h544c88 0 160-72 160-160V272c0-88-72-160-160-160zm96 640c0 52.8-43.2 96-96 96H240c-52.8 0-96-43.2-96-96V272c0-52.8 43.2-96 96-96h544c52.8 0 96 43.2 96 96v480z" fill="currentColor"></path><path d="M352 480c52.8 0 96-43.2 96-96s-43.2-96-96-96-96 43.2-96 96 43.2 96 96 96zm0-128c17.6 0 32 14.4 32 32s-14.4 32-32 32-32-14.4-32-32 14.4-32 32-32zm462.4 379.2-3.2-3.2-177.6-177.6c-25.6-25.6-65.6-25.6-91.2 0l-80 80-36.8-36.8c-25.6-25.6-65.6-25.6-91.2 0L200 728c-4.8 6.4-8 14.4-8 24 0 17.6 14.4 32 32 32 9.6 0 16-3.2 22.4-9.6L380.8 640l134.4 134.4c6.4 6.4 14.4 9.6 24 9.6 17.6 0 32-14.4 32-32 0-9.6-4.8-17.6-9.6-24l-52.8-52.8 80-80L769.6 776c6.4 4.8 12.8 8 20.8 8 17.6 0 32-14.4 32-32 0-8-3.2-16-8-20.8z" fill="currentColor"></path></svg></label><button type="button" class="wl-action" title="预览"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M710.816 654.301c70.323-96.639 61.084-230.578-23.705-314.843-46.098-46.098-107.183-71.109-172.28-71.109-65.008 0-126.092 25.444-172.28 71.109-45.227 46.098-70.756 107.183-70.756 172.106 0 64.923 25.444 126.007 71.194 172.106 46.099 46.098 107.184 71.109 172.28 71.109 51.414 0 100.648-16.212 142.824-47.404l126.53 126.006c7.058 7.06 16.297 10.979 26.406 10.979 10.105 0 19.343-3.919 26.402-10.979 14.467-14.467 14.467-38.172 0-52.723L710.816 654.301zm-315.107-23.265c-65.88-65.88-65.88-172.54 0-238.42 32.069-32.07 74.245-49.149 119.471-49.149 45.227 0 87.407 17.603 119.472 49.149 65.88 65.879 65.88 172.539 0 238.42-63.612 63.178-175.242 63.178-238.943 0zm0 0" fill="currentColor"></path><path d="M703.319 121.603H321.03c-109.8 0-199.469 89.146-199.469 199.38v382.034c0 109.796 89.236 199.38 199.469 199.38h207.397c20.653 0 37.384-16.645 37.384-37.299 0-20.649-16.731-37.296-37.384-37.296H321.03c-68.582 0-124.352-55.77-124.352-124.267V321.421c0-68.496 55.77-124.267 124.352-124.267h382.289c68.582 0 124.352 55.771 124.352 124.267V524.72c0 20.654 16.736 37.299 37.385 37.299 20.654 0 37.384-16.645 37.384-37.299V320.549c-.085-109.8-89.321-198.946-199.121-198.946zm0 0" fill="currentColor"></path></svg></button></div><div class="wl-info"><div class="wl-captcha-container"></div><div class="wl-text-number">0 <span>  /  <span class="">300</span></span>  字</div><button type="button" class="wl-btn">登录</button><button type="submit" class="primary wl-btn" title="Cmd|Ctrl + Enter"><!--[-->提交<!--]--></button></div><div class="wl-gif-popup"><input type="text" placeholder="搜索表情包"><!--v-if--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div></div><div class="wl-emoji-popup"><!--[--><!--]--><!--v-if--></div></div></div><!--v-if--></div><div class="wl-meta-head"><div class="wl-count"><!--v-if--> 评论</div><ul class="wl-sort"><!--[--><li class="active">按正序</li><li class="">按倒序</li><li class="">按热度</li><!--]--></ul></div><div class="wl-cards"><!--[--><!--]--></div><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div><div class="wl-power"> Powered by <a href="https://github.com/walinejs/waline" target="_blank" rel="noopener noreferrer"> Waline </a> v3.3.2</div></div></div><!----><!--]--></main><!--]--><div style="--0dfcb062:;"><footer class="footer-wrapper" style="display:none;"><div class="busuanzi"><span id="busuanzi_container_site_pv" style="display:none;"> 本站总访问量 <span id="busuanzi_value_site_pv"></span>次 <span class="post-meta-divider">|</span></span><span id="busuanzi_container_site_uv" style="display:none;"> 您是本站第 <span id="busuanzi_value_site_uv"></span>位访问者 </span></div><div class="footer-content"><div class="footer">默认页脚</div><div class="copyright">Copyright © 2020-2025 MrJason</div></div><span id="runtime_span"></span><div class="footer-link"><a href="https://www.foreverblog.cn/go.html" target="_blank"><img src="https://img.foreverblog.cn/wormhole_1.gif" alt="" style="width:auto;height:32px;" title="穿梭虫洞-随机访问十年之约友链博客"></a><a href="https://www.travellings.cn/go.html" target="_blank"><img src="https://www.travellings.cn/assets/logo.gif" alt="" style="width:auto;height:32px;" title="开往-友链接力"></a></div></footer></div></div><!--]--><!--[--><!----><!----><div></div><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-4x2aIoqi.js" defer></script>
  </body>
</html>
