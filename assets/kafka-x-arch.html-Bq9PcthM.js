import{_ as a,c as r,a as o,o as t}from"./app-4x2aIoqi.js";const i={};function n(s,e){return t(),r("div",null,e[0]||(e[0]=[o(`<h1 id="kafka-架构" tabindex="-1"><a class="header-anchor" href="#kafka-架构"><span>Kafka - 架构</span></a></h1><h2 id="_1-kafka的架构" tabindex="-1"><a class="header-anchor" href="#_1-kafka的架构"><span>1. Kafka的架构</span></a></h2><figure><img src="https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939997.png" alt="image-20220921201525148" tabindex="0" loading="lazy"><figcaption>image-20220921201525148</figcaption></figure><p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p><h2 id="_2-topics和partition" tabindex="-1"><a class="header-anchor" href="#_2-topics和partition"><span>2. Topics和Partition</span></a></h2><p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时也会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p><figure><img src="https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939054.png" alt="image-20220921204223339" tabindex="0" loading="lazy"><figcaption>image-20220921204223339</figcaption></figure><p>对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置<code>$KAFKA_HOME/config/server.properties</code>，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示：</p><div class="language-properties" data-ext="properties" data-title="properties"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># The minimum age of a log file to be eligible for deletion</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log.retention.hours</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">168</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log.segment.bytes</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">1073741824</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># The interval at which log segments are checked to see if they can be deleted according to the retention policies</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log.retention.check.interval.ms</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">300000</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction.</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log.cleaner.enable</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">false</span></span></code></pre></div><p>因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。</p><h2 id="_3-producer消息路由" tabindex="-1"><a class="header-anchor" href="#_3-producer消息路由"><span>3. Producer消息路由</span></a></h2><p>Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。可以在<code>$KAFKA_HOME/config/server.properties</code>中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。</p><p>在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的paritition. class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。</p><h2 id="_4-consumer-group" tabindex="-1"><a class="header-anchor" href="#_4-consumer-group"><span>4. Consumer Group</span></a></h2><p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。</p><figure><img src="https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939096.png" alt="image-20220921204823790" tabindex="0" loading="lazy"><figcaption>image-20220921204823790</figcaption></figure><p>这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。</p><p>实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。</p><h2 id="_5-push-vs-pull" tabindex="-1"><a class="header-anchor" href="#_5-push-vs-pull"><span>5. Push vs. Pull</span></a></h2><p>作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。一些logging-centric system，比如Facebook的Scribe和Cloudera的Flume，采用push模式。事实上，push模式和pull模式各有优劣。</p><p>push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。</p><p>对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p><h2 id="_6-kafka-delivery-guarantee" tabindex="-1"><a class="header-anchor" href="#_6-kafka-delivery-guarantee"><span>6. Kafka delivery guarantee</span></a></h2><p>有这么几种可能的delivery guarantee：</p><blockquote><p>At most once 　　消息可能会丢，但绝不会重复传输</p><p>At least one 　　 消息绝不会丢，但可能会重复传输</p><p>Exactly once 　　 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。</p></blockquote><p>当Producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。但是如果Producer发送数据给broker后，遇到网络问题而造成通信中断，那Producer就无法判断该条消息是否已经commit。虽然Kafka无法确定网络故障期间发生了什么，但是Producer可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了Exactly once。</p><p>接下来讨论的是消息从broker到Consumer的delivery guarantee语义。（仅针对Kafka consumer high level API）。Consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中保存该Consumer在该Partition中读取的消息的offset。该Consumer下一次再读该Partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将Consumer设置为autocommit，即Consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际使用中应用程序并非在Consumer读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。</p><p><strong>Kafka默认保证At least once</strong>，并且允许通过设置Producer异步提交来实现At most once。而Exactly once要求与外部存储系统协作，幸运的是Kafka提供的offset可以非常直接非常容易得使用这种方式。</p><h2 id="参考文章" tabindex="-1"><a class="header-anchor" href="#参考文章"><span>参考文章</span></a></h2><p><a href="https://www.cnblogs.com/qingyunzong/p/9004593.html" target="_blank" rel="noopener noreferrer">Kafka学习之路 （二）Kafka的架构</a></p>`,30)]))}const l=a(i,[["render",n],["__file","kafka-x-arch.html.vue"]]),c=JSON.parse('{"path":"/posts/MiddleWare/MQ_KAFKA/kafka-x-arch.html","title":"Kafka - 架构","lang":"zh-CN","frontmatter":{"order":30,"category":["kafka","MQ"],"created":"2024-05-13 20:48","updated":"2024-10-26 09:39","description":"Kafka - 架构 1. Kafka的架构 image-20220921201525148image-20220921201525148 如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数...","watermark":true,"head":[["meta",{"property":"og:url","content":"https://springg.us.kg/posts/MiddleWare/MQ_KAFKA/kafka-x-arch.html"}],["meta",{"property":"og:site_name","content":"mrjason’s Blog"}],["meta",{"property":"og:title","content":"Kafka - 架构"}],["meta",{"property":"og:description","content":"Kafka - 架构 1. Kafka的架构 image-20220921201525148image-20220921201525148 如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939997.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-28T01:58:08.000Z"}],["meta",{"property":"article:author","content":"MrJason"}],["meta",{"property":"article:modified_time","content":"2024-10-28T01:58:08.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka - 架构\\",\\"image\\":[\\"https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939997.png\\",\\"https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939054.png\\",\\"https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939096.png\\"],\\"dateModified\\":\\"2024-10-28T01:58:08.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"MrJason\\",\\"url\\":\\"https://springg.us.kg\\"}]}"]]},"headers":[{"level":2,"title":"1. Kafka的架构","slug":"_1-kafka的架构","link":"#_1-kafka的架构","children":[]},{"level":2,"title":"2. Topics和Partition","slug":"_2-topics和partition","link":"#_2-topics和partition","children":[]},{"level":2,"title":"3. Producer消息路由","slug":"_3-producer消息路由","link":"#_3-producer消息路由","children":[]},{"level":2,"title":"4. Consumer Group","slug":"_4-consumer-group","link":"#_4-consumer-group","children":[]},{"level":2,"title":"5. Push vs. Pull","slug":"_5-push-vs-pull","link":"#_5-push-vs-pull","children":[]},{"level":2,"title":"6. Kafka delivery guarantee","slug":"_6-kafka-delivery-guarantee","link":"#_6-kafka-delivery-guarantee","children":[]},{"level":2,"title":"参考文章","slug":"参考文章","link":"#参考文章","children":[]}],"git":{"createdTime":1730080688000,"updatedTime":1730080688000,"contributors":[{"name":"MrJason","email":"845886914@qq.com","commits":1}]},"readingTime":{"minutes":7.3,"words":2190},"filePathRelative":"posts/MiddleWare/MQ_KAFKA/kafka-x-arch.md","localizedDate":"2024年10月28日","excerpt":"\\n<h2>1. Kafka的架构</h2>\\n<figure><img src=\\"https://cdn.jsdelivr.net/gh/MrJackC/PicGoImages/other/202410260939997.png\\" alt=\\"image-20220921201525148\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>image-20220921201525148</figcaption></figure>\\n<p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>","autoDesc":true}');export{l as comp,c as data};
