import{_ as a,c as n,a as i,o as l}from"./app-tJW29Kmg.js";const e={};function r(o,s){return l(),n("div",null,s[0]||(s[0]=[i(`<h1 id="kafka总结" tabindex="-1"><a class="header-anchor" href="#kafka总结"><span>Kafka总结</span></a></h1><hr><h2 id="一、kafka概述" tabindex="-1"><a class="header-anchor" href="#一、kafka概述"><span>一、kafka概述</span></a></h2><h3 id="_1-1-kafka定义" tabindex="-1"><a class="header-anchor" href="#_1-1-kafka定义"><span>1.1 kafka定义</span></a></h3><blockquote><p>Kafka是一个分布式的基于<strong>发布/订阅</strong>模式的<strong>消息队列，<strong>主要应用于大数据</strong>实时</strong>处理领域。</p><p>订阅式模式：一对多的关系，一个生产者，数据存储在消息队列中，多个消费者均可从这个消息对列中获取数据，<strong>消费者消费数据之后不会清除消息。</strong></p></blockquote><h3 id="_1-2-框架说明" tabindex="-1"><a class="header-anchor" href="#_1-2-框架说明"><span>1.2 框架说明</span></a></h3><blockquote><p>一般都是从命令行和API两个方面进行讲解。</p><p>数据处理框架需要从数据的安全性以及效率两个方面深入了解。</p></blockquote><h3 id="_1-3-kafka涉及的关键词" tabindex="-1"><a class="header-anchor" href="#_1-3-kafka涉及的关键词"><span>1.3 Kafka涉及的关键词</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. producer: 消息的生产者，即为向kafka broker发消息;</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#C678DD;--shiki-dark:#C678DD;">broker</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ： kafka集群的节点；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. topic : 队列（话题），生产者和消费者面向的都是一个topic；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#C678DD;--shiki-dark:#C678DD;">message</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：消息，队列中的一条消息；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#C678DD;--shiki-dark:#C678DD;">partition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">: 分区，为方便扩展和提高吞吐量，将一个topic分为了多个partition；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">6</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#C678DD;--shiki-dark:#C678DD;">index</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ： 消息数据在log文件中的索引；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">7</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. </span><span style="color:#C678DD;--shiki-dark:#C678DD;">log</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ：消息的具体数据；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">8</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. timeindex： 时间索引，代表发送的数据时间索引；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">9</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. offset ： 消息的偏移量，每一条消息都对应一个offset；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">10</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. segment : 一个分片数据；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">11</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. leader ：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">12</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. follower : 每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader</span></span></code></pre></div><h2 id="二、kafka安装" tabindex="-1"><a class="header-anchor" href="#二、kafka安装"><span>二、Kafka安装</span></a></h2><h3 id="_2-1-集群部署" tabindex="-1"><a class="header-anchor" href="#_2-1-集群部署"><span>2.1 集群部署</span></a></h3><h4 id="_2-2-1-解压安装包" tabindex="-1"><a class="header-anchor" href="#_2-2-1-解压安装包"><span>2.2.1 解压安装包</span></a></h4><p>在/opt/software目录下</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">tar -zxvf </span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">11</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.tgz -C /opt/module/</span></span></code></pre></div><h4 id="_2-2-2-修改解压后的文件名称" tabindex="-1"><a class="header-anchor" href="#_2-2-2-修改解压后的文件名称"><span>2.2.2 修改解压后的文件名称</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> mv </span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka_2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">11</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/ kafka</span></span></code></pre></div><h4 id="_2-2-3-创建logs文件夹" tabindex="-1"><a class="header-anchor" href="#_2-2-3-创建logs文件夹"><span>2.2.3 创建logs文件夹</span></a></h4><p>在/opt/module/kafka目录下</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">mkdir logs</span></span></code></pre></div><h4 id="_2-2-4-修改配置文件" tabindex="-1"><a class="header-anchor" href="#_2-2-4-修改配置文件"><span>2.2.4 修改配置文件</span></a></h4><p>/opt/module/kafk路径下</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">vim config/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">properties</span></span></code></pre></div><p>修改如下三个参数，修改后的值如下：</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">broker</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">id</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">log</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">dirs</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/opt/module/kafka/logs</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">zookeeper</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">connect</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop102:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2181</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop103:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2181</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop104:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2181</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/kafka</span></span></code></pre></div><h4 id="_2-2-5-配置环境变量" tabindex="-1"><a class="header-anchor" href="#_2-2-5-配置环境变量"><span>2.2.5 配置环境变量</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">sudo vim /etc/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">profile</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">d</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">my_env</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><p>增加如下配置：</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">#KAFKA_HOME</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">KAFKA_HOME</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/opt/module/kafka</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">PATH</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$</span><span style="color:#C678DD;--shiki-dark:#C678DD;">PATH</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">:$KAFKA_HOME/bin</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export KAFKA_HOME</span></span></code></pre></div><p>生效配置文件：</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">source /etc/</span><span style="color:#C678DD;--shiki-dark:#C678DD;">profile</span></span></code></pre></div><h4 id="_2-2-6-分发安装包" tabindex="-1"><a class="header-anchor" href="#_2-2-6-分发安装包"><span>2.2.6 分发安装包</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">xsync kafka/</span></span></code></pre></div><p>注意：分发之后记得配置其他机器的环境变量</p><h4 id="_2-2-7-修改其他机器的配置文件" tabindex="-1"><a class="header-anchor" href="#_2-2-7-修改其他机器的配置文件"><span>2.2.7 修改其他机器的配置文件</span></a></h4><ul><li><p>/opt/module/kafka/config/server.properties中的broker.id=3、broker.id=4</p><p>注：broker.id不得重复</p></li></ul><h4 id="_2-2-8-启动集群" tabindex="-1"><a class="header-anchor" href="#_2-2-8-启动集群"><span>2.2.8 启动集群</span></a></h4><ol><li><p>首先启动zookeeper集群和hadoop集群</p></li><li><p>依次在hadoop102、hadoop103、hadoop104节点上启动kafka</p></li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> -daemon $KAFKA_HOME/config/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">properties</span></span></code></pre></div><ul><li>-daemon属于后台启动，没有-daemon则为前台启动</li></ul><h4 id="_2-2-9-关闭集群" tabindex="-1"><a class="header-anchor" href="#_2-2-9-关闭集群"><span>2.2.9 关闭集群</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">stop</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><h4 id="_2-2-10-kafka群起群停脚本" tabindex="-1"><a class="header-anchor" href="#_2-2-10-kafka群起群停脚本"><span>2.2.10 kafka群起群停脚本</span></a></h4><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">#！bin/bash</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">if</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> [ $# -lt 1 ]</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;"> then</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">   echo </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;No Args Input Error&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">   exit</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">fi</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">case</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> $</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> in</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&quot;start&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">for</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> i </span><span style="color:#C678DD;--shiki-dark:#C678DD;">in</span><span style="color:#98C379;--shiki-dark:#98C379;"> \`cat /opt/module/hadoop-3.1.3/etc/hadoop/workers\`</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">do</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">echo </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;==========start $i kafka==========&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">ssh $i </span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;$KAFKA_HOME/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties&#39;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">done</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;;</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&quot;stop&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">for</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> i </span><span style="color:#C678DD;--shiki-dark:#C678DD;">in</span><span style="color:#98C379;--shiki-dark:#98C379;"> \`cat /opt/module/hadoop-3.1.3/etc/hadoop/workers\`</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">do</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">echo </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;==========stop $i kafka==========&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">ssh $i </span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;$KAFKA_HOME/bin/kafka-server-stop.sh&#39;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">done</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">*)</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">  echo </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;Input Args Error&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">esac</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-kafka命令操作" tabindex="-1"><a class="header-anchor" href="#_2-2-kafka命令操作"><span>2.2 Kafka命令操作</span></a></h3><h4 id="_2-2-1-查看当前服务器中的所有topic" tabindex="-1"><a class="header-anchor" href="#_2-2-1-查看当前服务器中的所有topic"><span>2.2.1 查看当前服务器中的所有topic</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">topics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  --bootstrap-server hadoop102:9092 --list</span></span></code></pre></div><p>选项说明：</p><ul><li>--list ：查看kafka所有的topic</li><li>--bootstrap-server : 连接kafka集群</li><li>--hadoop102:9092：hadoop102是指连接kafka任意一台机器，9092：kafka内部通信的端口</li></ul><h4 id="_2-2-2-创建topic" tabindex="-1"><a class="header-anchor" href="#_2-2-2-创建topic"><span>2.2.2 创建topic</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">topics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  --bootstrap-server hadoop102:9092 --create --topic first --partitions 2 --replication-factor 2</span></span></code></pre></div><p>选项说明：</p><ul><li>--topic : 定义topic名字</li><li>--partitions : 定义分区数</li><li>--replication-factor : 定义副本数</li></ul><h4 id="_2-2-3-查看某个topic的详情" tabindex="-1"><a class="header-anchor" href="#_2-2-3-查看某个topic的详情"><span>2.2.3 查看某个Topic的详情</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> kafka-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">topics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --bootstrap-server hadoop102:9092 --describe --topic first</span></span></code></pre></div><p>选项说明：</p><ul><li>--topic first ： 查看指定的话题，如果不加此选项，则表示查看所有的话题</li></ul><h4 id="_2-2-4-修改分区数" tabindex="-1"><a class="header-anchor" href="#_2-2-4-修改分区数"><span>2.2.4 修改分区数</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">topics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --bootstrap-server hadoop102:9092 --alter --topic first --partitions 6</span></span></code></pre></div><p>说明：</p><ul><li>--分区数只能增加不能减少</li><li>分区内部消息有序，分区之间消息无序</li></ul><h4 id="_2-2-5-发送消息" tabindex="-1"><a class="header-anchor" href="#_2-2-5-发送消息"><span>2.2.5 发送消息</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-console-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --broker-list  hadoop102:9092,hadoop103:9092,hadoop104:9092 --topic first</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hello world</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">atguigu  atguigu</span></span></code></pre></div><p>选项说明：</p><ul><li>hadoop102:9092,hadoop103:9092,hadoop104:9092 : kafka的集群中的broker，其实写一个也是可以的，写3个的目的只是避免当连接的kafka集群broker故障时连不上kafka集群的情况。</li></ul><h4 id="_2-2-6-消费消息" tabindex="-1"><a class="header-anchor" href="#_2-2-6-消费消息"><span>2.2.6 消费消息</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-console-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">consumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --bootstrap-server hadoop102:9092 --from-beginning --topic first</span></span></code></pre></div><p>选项说明：</p><ul><li><p>--from-beginning ：</p><p>加上：会把topic中以往所有的数据都读取出来</p><p>不加：此时只会消费最新的数据，原来topic中的数据不会被消费</p></li></ul><h4 id="_2-2-7-删除topic" tabindex="-1"><a class="header-anchor" href="#_2-2-7-删除topic"><span>2.2.7 删除topic</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">topics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --bootstrap-server hadoop102:9820 --delete --topic first</span></span></code></pre></div><h2 id="三、-kafka深入流程" tabindex="-1"><a class="header-anchor" href="#三、-kafka深入流程"><span>三、 Kafka深入流程</span></a></h2><p>说明：此框架步步引导，采取提出问题解决问题的方式阐述。</p><h3 id="_3-1-kafka工作流程及文件存储机制" tabindex="-1"><a class="header-anchor" href="#_3-1-kafka工作流程及文件存储机制"><span>3.1 Kafka工作流程及文件存储机制</span></a></h3><p>![图2](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200529005434.png)</p><ol><li>kafka 以topic（话题）为单位，每一个话题分为多个区（创建话题的时候指定分区的个数），每个分区中存储的数据是不一样的，同时每个分区的数据在其他分区也会创建副本。</li><li>不同的分区分布在kafka集群不同的机器（broker，代理人）上面；</li><li>消息的生产和消费均是分区为单位；</li><li>分区内的数据是有序的，分区之间的顺序是无序的；</li><li>offset 指消息的偏移量；</li><li>每个分区都是一个文件夹，文件中包含index（数据在log中的索引）、log（真实的数据）、timeindex (数据发送的时间索引) ，时间索引和index索引均是用来提高查询数据效率；</li><li>当产生新的数据以后会向log文件中进行追加，同时index和timeindex也会增加；</li><li>Kafka采取了<strong>分片</strong>和<strong>索引</strong>机制。</li><li>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费</li></ol><p>![图1](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200610151457.png)</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问1：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">产生的数据一直向同一个log中进行追加，会有什么问题呢？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">log中的数据会越来越大，查询和读取效率会变慢。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 解决方式：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">数据达到一定程度以后（默认值为1G：</span><span style="color:#D19A66;--shiki-dark:#D19A66;">log</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">segment</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.bytes </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> 1G），log会进行数据切分，生成多个segment切分文件。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">切分后的文件依然包含index、</span><span style="color:#C678DD;--shiki-dark:#C678DD;">log</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">、timeindex 。所以三个文件是作为一个整体的。 </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--切分机制</span></span></code></pre></div><p>![image-20200714205920775](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200714205928.png)</p><p>![image-20200714210619003](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200714210619.png)</p><blockquote><p>切分的文件位于同一个文件夹下，该文件夹的命名规则为：<mark>topic名称+分区序号</mark>。</p><p>例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2</p></blockquote><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问2：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">现在假如有两个切分的文件，当有一个消费者需要消费一条消息（假如是 offset </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">），怎么知道这个消息在哪个切分文件中，以及真实数据如何查询？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--答案：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）log和index文件名说明： </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 牢记log、index、timeindex是一个整体</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">index</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：</span><span style="color:#D19A66;--shiki-dark:#D19A66;">00000000000000000000</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">index</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">log</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：</span><span style="color:#D19A66;--shiki-dark:#D19A66;">00000000000000000000</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">log</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">前面的数字00000000000000000000：代表此log文件中第一条消息的offset。</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&#39;.index文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址&#39;</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 查询的方式：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">根据消费消息的offset值 </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--&gt;找到指定的index文件 --&gt; 匹配此条消息在log文件中数据的偏移量（即该数据在log文件中起始位置）--&gt; 找到待消费的数据</span></span></code></pre></div><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问3：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">为什么kafka要采取向一个log文件中追加数据呢？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）减少IO；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）消费数据是连续进行消费，连续读取数据的效率高。</span></span></code></pre></div><h3 id="_3-2-kafka之生产者producer" tabindex="-1"><a class="header-anchor" href="#_3-2-kafka之生产者producer"><span>3.2 Kafka之生产者producer</span></a></h3><h4 id="_3-2-1-分区策略" tabindex="-1"><a class="header-anchor" href="#_3-2-1-分区策略"><span>3.2.1 分区策略</span></a></h4><ol><li>首先producer发送的数据会被封装成 ProducerRecord 对象，根据对象的参数，分区情况如下： <ul><li><p>情况1 ：指定了partition；</p></li><li><p>情况2 ：未指定partition，封装key，则按照key的hashcode % 分区数量 得出在哪个分区；</p></li><li><p>情况3：未指定partition，也未封装key处理方式 :</p><p>参数1：producer发送的数据量：batch.size，默认值为16Kb；</p><p>条件2：<a href="http://linger.ms" target="_blank" rel="noopener noreferrer">linger.ms</a>：两条数据发送的间隔时间 t ，默认值为0s；</p><p>当发送的数据量 &lt; batch.size 并且 发送的数据时间间隔 &lt; t 时，所有的数据在一个分区；</p><p>当发送的数据量 &gt; batch.size 或者 发送的数据时间间隔 &gt; t 时，则数据会进入下一个分区；</p><p>分区与分区之间采取轮询的方式。</p><p>![图4](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200529005453.png)</p><p>![图3](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200529005450.png)</p></li></ul></li></ol><h4 id="_3-2-2-数据可靠性保证" tabindex="-1"><a class="header-anchor" href="#_3-2-2-数据可靠性保证"><span>3.2.2 数据可靠性保证</span></a></h4><p>数据传输流程：</p><p>producer -----&gt; server（kafka） ---------&gt;消费者</p><ul><li>过程1：producer -----&gt; server（kafka）</li></ul><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问1： </span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">如何保证从producer发送数据server的过程中数据不丢失？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">server收到数据以后会回执，发送ack（acknowledgement确认收到）给producer，producer收到ack以后，则确定数据传送的过程中没有丢失。</span></span></code></pre></div><ul><li>过程2 ： server的数据存储过程</li></ul><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问2：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">如何确保数据在server中能够被妥善保管呢？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">server向producer回执ack的时机：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">模式1：leader收到消息以后立即回复ack；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">模式2：leader收到消息并存储在本地以后，立即回复ack；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">模式3：leader收到消息后，所有follow从leader中拉取数据，当所有的follower完成存储以后，leader向producer回复ack。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">说明：情况1/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/3是通过acks参数进行配置。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">acks</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">0</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> -- leader收到消息以后立即回复ack</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">acks</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> -- leader收到消息并存储在本地以后，立即回复ack</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">acks</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-1或all </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--leader收到消息后，所有follow从leader中拉取数据，当所有的follower完成存储以后，leader向producer回复ack</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 默认情况下是acks=1；</span></span>
<span class="line"></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">===============================================================================</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问3：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">leader与follower副本数据同步策略是什么呢？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">两种副本同步策略。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第一种：半数以上完成同步，就发送ack</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第二种：全部完成同步，才发送ack</span></span>
<span class="line"></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&#39;kafka选择全部完成同步，才发送ack&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">================================================================================</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 灵魂拷问4：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka选择第二种副本同步策略会有哪些问题呢？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">问题1：follower同步leader的数据时，当某一个follower迟迟未向leader回复备份成功时，出现阻塞的状态；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">问题2：当leader回执给producer的ack丢失时，producer因为没有收到来自leader的ack，则默认数据没有发送成功，会重新向集群发送未收到ack的消息，导致数据的重复。 </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 数据的重复指：同一条消息重复发送。</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 那如何解决这两个问题呢？</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>问题1（数据阻塞）解决方案：</li></ul><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">规则：leader完成消息的读取和写出操作，follower定时向leader拉取数据。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. leader维护了一个动态的in-sync replicat </span><span style="color:#C678DD;--shiki-dark:#C678DD;">set</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (ISR) 同步副本的列表，说明：即使是follower也有可能不在isr列表中。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.。只要在isr列表中所有的follower均告知leader副本备份完成以后，则leader向producer回执ack，则不受限于出现故障的follower，因为出现故障，就被移除isr列表中。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题1：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">那么什么情况下follower不在isr列表呢？</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">如果follower没有在规定的时间与leader保持同步，则leader会将该follower从isr中踢出，</span><span style="color:#D19A66;--shiki-dark:#D19A66;">同步最大时间通过replica</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">lag</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">time</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">max</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">ms参数设定</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题2：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">那么从isr中踢出的follower怎么重新回到isr中呢？ </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--故障处理机制</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">每个消息在follower的log文件中有：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) 真实数据 :消息的真实数据</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) LEO(</span><span style="color:#C678DD;--shiki-dark:#C678DD;">log</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> end</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> offset) : 消息的最后偏移量</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) HW(High Watermark) ：ISR列表中follower最小的LEO（偏移量）</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">说明：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）每个follower中的LEO可能是不一样的，因副本同步的快慢有差异；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）leader中log的LEO是最大的，因为数据源源不断的发送过来，它的落盘速度是最快的；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）HW之前的数据对consumer可见；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）HW是一个动态的数据，当leader回执ack一次HW就会更新一次。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题3：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">当leader挂掉以后怎么办？</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 重新选举leader；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 从isr列表中的follower中选取；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 随机选择。</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&#39;详细过程&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&#39;注意&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>问题2（数据重复）的解决方案</li></ul><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 在0.11之前的kafka版本：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">在消费者端进行去重，在producer传输数据时，对消息增加唯一的全局主键，然后在消费端根据该主键进行去重。 </span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">该方式导致消费者组所有的消费者都需要进行去重操作，重复。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 在0.11版本之后引进了 Exactly Once （幂等性）来解决数据重复的问题</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;"> 1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） Exactly Once （幂等性） ： 做n次和做一次的效果是一样的，就是指Producer不论向Server发送多少次重复数据（重复发送同一条数据），Server端都只会持久化一条，在server端完成去重操作。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;"> 2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 幂等性实现过程</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">   初始化数据时，给消息分配一个pid，发往同一个分区的消息会附带sequence </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Number</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,broker端会将</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">pid,</span><span style="color:#C678DD;--shiki-dark:#C678DD;">partition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span><span style="color:#C678DD;--shiki-dark:#C678DD;">sequence</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> Number</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">和消息的真实数据一起存储到log文件中，当具有相同主键的消息提交时，Broker只会持久化一条。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 何为主键？</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">由</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">pid,</span><span style="color:#C678DD;--shiki-dark:#C678DD;">partition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span><span style="color:#C678DD;--shiki-dark:#C678DD;">sequence</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> Number</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">三个参数构成的集合。重复发送的数据，这三个值不会变，数据是否重复与数据的内容无关，而是指为同一条数据多次发送。 </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 总结：重发的消息的主键是不会改变的，新发的消息seqnumber就会变化。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">例如：消息A与消息B的数据内容完全一致</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">producer向集群发送消息A，集群收到以后返回的ack丢失，则消息A会被再次发送一次，此时消息A的主键是和第一次发送时相同，则集群认为数据是重复，不会进行存储；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">producer向集群发送消息B，虽然与消息A的数据相同，但是seqnumber是不同的，所以不是重复的数据，集群会进行数据存储。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">说明：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） </span><span style="color:#C678DD;--shiki-dark:#C678DD;">sequence</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> Number</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ：消息序列号，发往同一Partition的消息会附带Sequence </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Number</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">，表示该producer向该分区发送的第几次消息；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)	pid : 生产者的id； </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)  </span><span style="color:#C678DD;--shiki-dark:#C678DD;">partition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ： 分区号；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 开启幂等性会降低kafka的性能；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">6</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 幂等性的底层原理也还是通过给消息增加全局的唯一主键的方式；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">7</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 开启幂等性参数：</span><span style="color:#D19A66;--shiki-dark:#D19A66;">enable</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">idompotence设置为true即可</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">。</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-3-kafka之消费者-consumer" tabindex="-1"><a class="header-anchor" href="#_3-3-kafka之消费者-consumer"><span>3.3 Kafka之消费者 consumer</span></a></h3><h4 id="_3-3-1-消费模式" tabindex="-1"><a class="header-anchor" href="#_3-3-1-消费模式"><span>3.3.1 消费模式</span></a></h4><p>​ 消费者从server中读取数据的方式有两种：pull （拉）和 push（推）</p><ol><li><p>pull ： consumer向server拉取数据 <strong>【主动】</strong></p><ul><li>优点：消费者按需索取</li><li>缺点：不及时，有可能拉取到了空数据</li></ul></li><li><p>push ：server向consumer推送数据**【被动】**</p><ul><li>优点：及时</li><li>缺点：推送的速率与消费者消费的数据不一致时，产生背压</li></ul></li><li><p>kafka默认使用pull，拉取数据的方式。因为kafka是一对多的关系，同一个消费者组内的不同消费者的消费速率不同，所以不好设定推送的速率。</p></li><li><p>当出现拉取的数据为空时，consumer会等待一段时间之后再拉取数据，这段时长即为timeout</p></li></ol><h4 id="_3-3-2-分区分配策略" tabindex="-1"><a class="header-anchor" href="#_3-3-2-分区分配策略"><span>3.3.2 分区分配策略</span></a></h4><p>​ 三种方式：roundrobin 、 range 、sticky</p><ol><li><p>roundrobin ： 轮询的方式 ，理解为洗牌，一张一张的发，分区一个一个轮询的方式分配给消费者；</p><p>缺点：当有新的消费者加进来时，所有的分区需要重新分配分区，基本上大多数的消费者的消费分区都会发生改变。</p></li><li><p>range：理解斗地主把牌按数量平均分配；</p><p>缺点：订阅的话题过多时，存在分区数量不均等的情况。</p></li><li><p>sticky：是在第一种方式的基础上进行改进，解决新增消费者情况的缺点，此时不再是所有消费者的分区进行重新分配，而是新进的消费者取之前所有消费者最后一次分区的数据进行消费。</p></li></ol><ul><li>当消费者的个数 &gt; 分区的个数时，有些消费者没分配不到数据。</li><li>消费者默认的分区分配策略是range，但是消费者在消费数据时也可以自定指定策略。</li><li>一个分区只能由一个消费者进行消费。</li></ul><h4 id="_3-3-3-offset的维护" tabindex="-1"><a class="header-anchor" href="#_3-3-3-offset的维护"><span>3.3.3 offset的维护</span></a></h4><p>​ 由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。<br> ​ Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">为什么要将offset从zookeeper中转移到kafka中？</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 回答：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">zookeeper中维护offset的效率对于Kafka来说，不可控的，Kafka不能通过修改自己的代码来提升zookeeper维护offset的效率，所以将offset的维护迁移到kafka的会话中。</span></span></code></pre></div><h3 id="_3-4-kafka高效读写数据" tabindex="-1"><a class="header-anchor" href="#_3-4-kafka高效读写数据"><span>3.4 Kafka高效读写数据</span></a></h3><h4 id="_3-4-1-顺序写磁盘" tabindex="-1"><a class="header-anchor" href="#_3-4-1-顺序写磁盘"><span>3.4.1 顺序写磁盘</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题1：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka的producer生产的数据最终按照顺序存储到磁盘上，写入到磁盘中数据过程不是很慢吗？</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 回答：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 多分区存储模式：kafka是采用多分区的存储方式，提高了高并发；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 顺序写模式：按照顺序写的速度能够减少大量磁头询地址的时间，使写数据速度和网络传输速度相当，所以基本上够用，但是还是比内存数据传输的速度要慢。</span></span></code></pre></div><h4 id="_3-4-2-应用pagecache" tabindex="-1"><a class="header-anchor" href="#_3-4-2-应用pagecache"><span>3.4.2 应用Pagecache</span></a></h4><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 1.说明：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">Pagecache(网页缓存)：是操作系统实现的一个功能，因为linux系统兼容这个功能，所以kafka能够使用，解决大量随机读写的过程。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 2.内存：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">我们常说的内存可以分为两个模块，一是提供给系统的内核使用，此部分对于用户是不可见的，不能被用户使用，二是供用户使用的内存。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 3.原理： </span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">pagecache是在内核内存中开辟的一个内存空间，producer生产的数据，先会存储在该内存中，待达到一定的数据量以后，再统一进行落盘，当消费者消费的速率和生产者生产的速率相同时，读写的效率是最高的，因为此时生产的数据不需要落盘处理，consumer直接从内存中读取数据。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 4.交换区和pagecache的区别：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">交换区：将磁盘当做内存使用；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">pagecache：将内存当做磁盘使用；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">恰好是两个相反的过程。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 5.假如pagecache挂掉了怎么办？内存中的数据不是丢失了吗？</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">首先当发生这个问题时，是不能够完全保证数据一定不丢失，但是由于kafka具有副本策略，所以有一定保证的。</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>优点：</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 读操作可直接在 </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Page</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Page</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Cache）交换数据</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 如果进程重启，JVM 内的 Cache 会失效，但 </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Page</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Cache 仍然可用</span></span></code></pre></div><h4 id="_3-4-3-零拷贝技术" tabindex="-1"><a class="header-anchor" href="#_3-4-3-零拷贝技术"><span>3.4.3 零拷贝技术</span></a></h4><p>![图5](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200529005509.png)</p><p>说明：</p><p>内存是分级别的，读写数据时数据先经过内核内存再经过用户内存。</p><p>如果是数据的写出操作，则数据经过内核内存以后就直接往外写出，不需经过用户内存，用户内存只是负责调度的功能，减少了 数据的传输过程，这个过程称为零拷贝。</p><h3 id="_3-5-zookeeper在kafka中的作用" tabindex="-1"><a class="header-anchor" href="#_3-5-zookeeper在kafka中的作用"><span>3.5 zookeeper在kafka中的作用</span></a></h3><ul><li>kafka是一个去中心化的框架，没有主从之分，则需要一个中央控制中心进行调度，类似ha集群一样。</li><li>kafka是依赖于zookeeper集群的。</li></ul><p>流程：一个kafka集群，多个broker，一个zk集群</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 步骤：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 首先所有的broker会竞选一个controller（随机竞选，谁厉害谁上），负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 所有的broker将自己的id信息注册到zk集群的节点上；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） controller监控zk的这个信息；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） controller负责broker的leader选举工作；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） broker将状态信息注册到zk集群上；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">6</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） 此时分区的leader故障以后，controller从zk集群中获取isr中的follower信息，负责从isr中follower选举出一个新的leader；</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">7</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">） controller更新zk集群上broker的状态信息。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 假如故障的leader恰好也是controller怎么办？</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">先从现存的follower中重新选举controller，再执行1-5步。</span></span></code></pre></div><p>![图6](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200529005514.png)</p><h3 id="_3-6-kafka事务" tabindex="-1"><a class="header-anchor" href="#_3-6-kafka事务"><span>3.6 Kafka事务</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--问题：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">事务用来解决什么问题？</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--回答：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka使用Exactly Once解决producer端生产数据重复的问题存在什么问题？</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">问题1：不能跨分区；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">问题2：producer重启时，pid会发生变化。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">则事务就是来解决上面问题的，事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 那具体是怎么做的呢？</span></span></code></pre></div><h4 id="_3-6-1-producer事务" tabindex="-1"><a class="header-anchor" href="#_3-6-1-producer事务"><span>3.6.1 producer事务</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--解决producer重启问题：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) 引进全局唯一的Transaction ID，将producer的pid与Transaction ID进行绑定。当重启producer时，可以通过正在进行的Transaction ID获得原来的PID.</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) 为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。</span><span style="color:#C678DD;--shiki-dark:#C678DD;">Transaction</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Coordinator还负责将所有事务写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</span></span></code></pre></div><h4 id="_3-6-2-consumer事务-精准一次性消费" tabindex="-1"><a class="header-anchor" href="#_3-6-2-consumer事务-精准一次性消费"><span>3.6.2 Consumer事务（精准一次性消费）</span></a></h4><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>kafak对consumer事务的保证是非常弱的，尤其无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况</span></span></code></pre></div><h2 id="四、-kafka-api" tabindex="-1"><a class="header-anchor" href="#四、-kafka-api"><span>四、 Kafka API</span></a></h2><p>温馨提示</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">api的步骤：</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第一步： new 对象;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第二步： 具体的操作;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第三步： 关闭资源。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 不知道要写哪些参数？不知道参数的意义？不知道参数取值？怎么办？</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">请认准kafka官网：https://</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">apache</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.org/documentation/</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">producer API ： 找Producer Configs</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">consumer API：  找Consumer Configs</span></span></code></pre></div><h3 id="_4-1-producer-api" tabindex="-1"><a class="header-anchor" href="#_4-1-producer-api"><span>4.1 Producer API</span></a></h3><h4 id="_4-1-1-消息发送流程" tabindex="-1"><a class="header-anchor" href="#_4-1-1-消息发送流程"><span>4.1.1 消息发送流程</span></a></h4><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题： </span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">Kafka的Producer发送消息采用的是异步发送的方式，这种方式优点和缺点是什么呢？</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 回答：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">优点：高效率，生产者只要一直生产数据就可以，不需要等到ack回执后再进行生产数据；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">缺点：不能实时知道数据是否发送成功，不过有ack机制、幂等性机制和producer事务（保证数据的准确性）。</span></span></code></pre></div><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 发送数据的流程：</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&#39;两线程一共享变量&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. main线程：将消息发送给RecordAccumulator</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. Sender线程：Sender线程不断从RecordAccumulator中拉取消息发送到Kafka </span><span style="color:#C678DD;--shiki-dark:#C678DD;">broker</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">. 线程共享变量——RecordAccumulator：数据临时存储器。</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">&#39;步骤&#39;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第一步：生产者首先将数据包装成ProducerRecord</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第二步：main线程中有一个send方法，producer将ProducerRecord发送给interceptors</span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;拦截器&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">处理；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第三步：interceptors处理好后将数据传递给</span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;序列化器&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">，将数据序列化； </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 在producer端序列化</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第四步：将序列化好的数据传递给</span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;分区器&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">，对数据进行分区； </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 在producer端序列化</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第五步：将数据传递到内存的数据缓存区，在这里面，话题有多少个分区，在缓存区里面就有多少个分区，一一对应，对应的分区数据就会去到对应的缓存区的分区中； </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 此时的数据是已经分好区了，同时也是已经序列化，此时producer就不再管这里的数据了；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">第六步：Sender线程就将数据发送给topic中的分区中。 </span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 此时的数据，Sender线程是怎么向topic中发的呢？</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">batch</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">size</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：</span><span style="color:#D19A66;--shiki-dark:#D19A66;">只有数据积累到batch</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">size之后</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">，sender才会发送数据。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">linger</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">ms</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">：</span><span style="color:#D19A66;--shiki-dark:#D19A66;">如果数据迟迟未达到batch</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">size</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">，</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sender等待linger</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">time之后就会发送数据</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">。</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>![图7](<a href="https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic" target="_blank" rel="noopener noreferrer">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</a> GO/20200529005518.png)</p><h4 id="_4-1-2-异步发送api" tabindex="-1"><a class="header-anchor" href="#_4-1-2-异步发送api"><span>4.1.2 异步发送API</span></a></h4><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">package</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> kafkaproducer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> org.apache.kafka.clients.producer.Callback</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> org.apache.kafka.clients.producer.KafkaProducer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> org.apache.kafka.clients.producer.ProducerRecord</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> org.apache.kafka.clients.producer.RecordMetadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.util.Properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.util.concurrent.ExecutionException</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.util.concurrent.Future</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">/**</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> * </span><span style="color:#C678DD;font-style:italic;--shiki-dark:#C678DD;--shiki-dark-font-style:italic;">@author</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> lianzhipeng</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> * @Description</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> * @create 2020-05-08 14:58</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> */</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> class</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> Producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> static</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> void</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> main</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[] </span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">args</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> throws</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> ExecutionException</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> InterruptedException</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //1.new 对象</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        Properties</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> properties</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> Properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;key.serializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                &quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;value.serializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                &quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;acks&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;all&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;bootstrap.servers&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;hadoop102:9092&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        KafkaProducer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;--shiki-dark:#E06C75;">producer</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> KafkaProducer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;(properties);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //2.具体的操作</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">        for</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (</span><span style="color:#C678DD;--shiki-dark:#C678DD;">int</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> i</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 0</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">; i </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 100</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">; i++) {</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">            Future</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RecordMetadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;--shiki-dark:#E06C75;">result</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">send</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#C678DD;--shiki-dark:#C678DD;">new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> ProducerRecord</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;(</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                    &quot;first&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                    &quot;Message&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> i,</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                    &quot;这是第&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> i </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;条信息&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            ), </span><span style="color:#C678DD;--shiki-dark:#C678DD;">new</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> Callback</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">() {</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//回调函数，当producer发送的数据完成以后，返回告诉producer数据发送成功</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">                public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> void</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> onCompletion</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">RecordMetadata</span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> metadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Exception</span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> exception</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">                    int</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> partition</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> metadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">partition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                    String</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> topic</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> metadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">topic</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">                    long</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> offset</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> metadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">offset</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                    System</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">out</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">println</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                            topic </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;话题&quot;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">                                    +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> partition </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;分区&quot;</span></span>
<span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">                                    +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> offset </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;消息发送成功&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                }</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            });</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            /*</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">           </span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            如下一行代码产生同步回调和异同回调两种方式：</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            同步回调：加了此行代码，生产者收到ack以后再发第二条消息；类似打电话</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            异步回调：未加此行代码，生成者只要一直发送消息既可。类似发短信</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">          </span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            */</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">            RecordMetadata</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> recordMetadata</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> result</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">get</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">            System</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">out</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">println</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;第&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> i </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;条消息发送结束&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        }</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //3.关闭资源，资源关闭的时候会调用回调函数</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">close</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    }</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-2-consumer-api" tabindex="-1"><a class="header-anchor" href="#_4-2-consumer-api"><span>4.2 Consumer API</span></a></h3><h4 id="_4-2-1-数据漏消费和重复消费" tabindex="-1"><a class="header-anchor" href="#_4-2-1-数据漏消费和重复消费"><span>4.2.1 数据漏消费和重复消费</span></a></h4><ol><li>消费者不用担心数据的可靠性问题，因为消费者消费以后的数据是不会从kafka集群中删除的。但是消费者要关心两个问题：</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题1 数据漏消费</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">什么时候会出现数据漏消费呢？</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">先提交offset后消费。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">例如：消费者从kafka集群中获取了数据，此数据在消费的过程中出现故障延迟最后宕机，在故障期间offset已经提交至kafka集群，此时实际上数据并没有被使用，但是kafka集群上该消费者消费的数据偏移量已经更新了，重启消费者时，上一条数据不能被消费了，导致数据漏消费。</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题2 数据重复消费</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">什么时候会出现数据库重复消费呢？</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">当数据已经被消费以后，此时返回的offset时消费者出现了故障，则kafka集群中的_consumer_offset会话保存的offset则为上一次的数据，offset没有被更新，当消费者重新启动时，上一条数据则会被重新再消费一次。</span></span></code></pre></div><ol start="2"><li>谈谈消费者提交offset的模式</li></ol><p>消费者每次拉取数据的最大值为：1M，（ 1048576字节）</p><ul><li><p>模式一：自动提交，默认每5s提交一次；</p></li><li><p>模式二：手动提交，两种方式：commitSync（同步提交）、commitAsync（异步提交）；</p></li></ul><p>​ 同步和异步的异同点：</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 相同点：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">提交本次poll的一批数据最高的偏移量.</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 不同点：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">commitSync（同步提交）：提交offset时，commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">commitAsync（异步提交）：则没有失败重试机制，故有可能提交失败。</span></span></code></pre></div><h4 id="_4-2-2-几个重要的参数" tabindex="-1"><a class="header-anchor" href="#_4-2-2-几个重要的参数"><span>4.2.2 几个重要的参数</span></a></h4><ol><li>自动提交offset的时间：默认为5s</li></ol><p><a href="https://kafka.apache.org/documentation/#auto.commit.interval.ms" target="_blank" rel="noopener noreferrer">auto.commit.interval.ms</a></p><table><thead><tr><th>Type:</th><th>int</th></tr></thead><tbody><tr><td>Default:</td><td>5000</td></tr><tr><td>Valid Values:</td><td>[0,...]</td></tr><tr><td>Importance:</td><td>low</td></tr></tbody></table><ol start="2"><li>消费者消费数据的起始位置</li></ol><p><a href="https://kafka.apache.org/documentation/#auto.offset.reset" target="_blank" rel="noopener noreferrer">auto.offset.reset</a></p><ul><li>earliest: automatically reset the offset to the earliest offset --&gt;表示消费topic所有的数据</li><li>latest: automatically reset the offset to the latest offset --&gt;表示只消费最新的数据</li></ul><table><thead><tr><th>Type:</th><th>string</th></tr></thead><tbody><tr><td>Default:</td><td>latest</td></tr><tr><td>Valid Values:</td><td>[latest, earliest, none]</td></tr><tr><td>Importance:</td><td>medium</td></tr></tbody></table><ol start="3"><li>一次从一个分区拉取的最大数据量</li></ol><p><a href="https://kafka.apache.org/documentation/#max.partition.fetch.bytes" target="_blank" rel="noopener noreferrer">max.partition.fetch.bytes</a></p><table><thead><tr><th>Type:</th><th>int</th></tr></thead><tbody><tr><td>Default:</td><td>1048576</td></tr><tr><td>Valid Values:</td><td>[0,...]</td></tr><tr><td>Importance:</td><td>high</td></tr></tbody></table><h4 id="_4-2-3-代码" tabindex="-1"><a class="header-anchor" href="#_4-2-3-代码"><span>4.2.3 代码</span></a></h4><ul><li><h3 id="consumer-api" tabindex="-1"><a class="header-anchor" href="#consumer-api"><span>Consumer API</span></a></h3></li></ul><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">package</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> kafkaconsumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> org.apache.kafka.clients.consumer.*</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> org.apache.kafka.common.TopicPartition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.time.Duration</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.util.Collections</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.util.Map</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">import</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> java.util.Properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">/**</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> * </span><span style="color:#C678DD;font-style:italic;--shiki-dark:#C678DD;--shiki-dark-font-style:italic;">@author</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> lianzhipeng</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> * @Description</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> * @create 2020-05-08 21:04</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> */</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> class</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> MyConsumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">    public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> static</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> void</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> main</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">[] </span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">args</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //1 new 对象</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        Properties</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> properties</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> Properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;key.deserializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;value.deserializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">                &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;bootstrap.servers&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;hadoop102:9092&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;group.id&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;group9&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;auto.offset.reset&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;earliest&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //自动提交offset</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        properties</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">setProperty</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;enable.auto.commit&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;false&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        KafkaConsumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;--shiki-dark:#E06C75;">consumer</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> new</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> KafkaConsumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;(properties);</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //2 操作</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //连接话题</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        consumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">subscribe</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Collections</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">singleton</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;first&quot;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">));</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //拉取数据</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">        Duration</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> duration</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> Duration</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">ofMillis</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#D19A66;--shiki-dark:#D19A66;">500</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">        while</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (</span><span style="color:#D19A66;--shiki-dark:#D19A66;">true</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">){</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">            ConsumerRecords</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;--shiki-dark:#E06C75;">records</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;"> consumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">poll</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(duration);</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">            for</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">ConsumerRecord</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">String</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;--shiki-dark:#E06C75;">record</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> :</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> records) {</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                System</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">out</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">println</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(record);</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            }</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            //手动同步提交</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//            consumer.commitSync();</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            //手动异步提交</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">            consumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">commitAsync</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#C678DD;--shiki-dark:#C678DD;">new</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> OffsetCommitCallback</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">() {</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                @</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Override</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">                public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> void</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> onComplete</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Map</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">TopicPartition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">OffsetAndMetadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">offsets</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Exception</span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> exception</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                    offsets</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">forEach</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                            (t, o) </span><span style="color:#C678DD;--shiki-dark:#C678DD;">-&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                                System</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">out</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">println</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;分区：&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> t </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\n</span><span style="color:#98C379;--shiki-dark:#98C379;">Offset：&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> o);</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                            }</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    );</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                }</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            });</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">        }</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        //3 关闭资源</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//        consumer.close();</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    }</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>异步提交代码：</li></ul><div class="language-java" data-ext="java" data-title="java"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//手动异步提交方式，形参里面为回调对象。</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">            consumer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">commitAsync</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#C678DD;--shiki-dark:#C678DD;">new</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> OffsetCommitCallback</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">() {</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                /*</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">               回调方式，当消费成功以后调用此方法并进行打印</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                */</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                @</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Override</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">                public</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> void</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> onComplete</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Map</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&lt;</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">TopicPartition</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">OffsetAndMetadata</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt; </span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">offsets</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">Exception</span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> exception</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                    offsets</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">forEach</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                            (t, o) </span><span style="color:#C678DD;--shiki-dark:#C678DD;">-&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="color:#E5C07B;--shiki-dark:#E5C07B;">                                System</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#E5C07B;--shiki-dark:#E5C07B;">out</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">println</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;分区：&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> t </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">+</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\n</span><span style="color:#98C379;--shiki-dark:#98C379;">Offset：&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> +</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> o);</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                            }</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                    );</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">                }</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">            });</span></span></code></pre></div><h2 id="五、kafka监控-kafka-eagle" tabindex="-1"><a class="header-anchor" href="#五、kafka监控-kafka-eagle"><span>五、Kafka监控（Kafka Eagle）</span></a></h2><ol><li>修改kafka启动命令</li></ol><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">修改kafka-</span><span style="color:#C678DD;--shiki-dark:#C678DD;">server</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">start</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh命令中</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--原文：</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">if</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">; </span><span style="color:#C678DD;--shiki-dark:#C678DD;">then</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    export KAFKA_HEAP_OPTS</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;-Xmx1G -Xms1G&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">fi</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--改为：</span></span>
<span class="line"><span style="color:#C678DD;--shiki-dark:#C678DD;">if</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">; </span><span style="color:#C678DD;--shiki-dark:#C678DD;">then</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    export KAFKA_HEAP_OPTS</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    export JMX_PORT</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;9999&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">    #export KAFKA_HEAP_OPTS</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;-Xmx1G -Xms1G&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">fi</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--注意：修改之后在启动Kafka之前要分发之其他节点</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>上传压缩包kafka-eagle-bin-1.3.7.tar.gz到集群/opt/software目录</li><li>解压到本地</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop102 software]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ tar -zxvf kafka-eagle-bin-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">7</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">tar</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">gz</span></span></code></pre></div><ol start="4"><li>进入刚才解压的目录,将kafka-eagle-web-1.3.7-bin.tar.gz解压至opt/module</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop102 kafka-eagle-bin-1.3.7]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> $ tar -zxvf kafka-eagle-web-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">4</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">5</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">bin</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">tar</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.gz -C /opt/module/</span></span></code></pre></div><ol start="5"><li>修改名称</li></ol><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>[atguigu@hadoop102 module]$ mv kafka-eagle-we-1.4.5/   eagle</span></span></code></pre></div><ol start="6"><li>给启动文件执行权限 /opt/module/eagle/bin</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop102 bin]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ chmod </span><span style="color:#D19A66;--shiki-dark:#D19A66;">777</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> ke</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span></span></code></pre></div><ol start="7"><li>修改配置文件 /opt/module/eagle/conf/system-config.properties</li></ol><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"># multi zookeeper&amp;kafka cluster list</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">zk</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">cluster</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.alias</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">cluster1</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">cluster1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">zk</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.list</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">hadoop102:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2181</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop103:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2181</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop104:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2181</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/kafka</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"># kafka offset storage</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">cluster1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">offset</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.storage</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kafka</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"># kafka metrics, </span><span style="color:#D19A66;--shiki-dark:#D19A66;">30</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> days</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> by</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> default</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">metrics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">charts</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">true</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">metrics</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">retain</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">30</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"># kafka sqlite jdbc driver </span><span style="color:#C678DD;--shiki-dark:#C678DD;">address</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">######################################</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.driver</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">com</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">mysql</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">jdbc</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">Driver</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">url</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">jdbc:mysql://hadoop102:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">3306</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/ke?useUnicode</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">true&amp;characterEncoding</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">UTF-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&amp;zeroDateTimeBehavior</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">convertToNull</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.username</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#C678DD;--shiki-dark:#C678DD;">root</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">password</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">123456</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="8"><li>添加环境变量</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export KE_HOME</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/opt/module/eagle</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">export </span><span style="color:#C678DD;--shiki-dark:#C678DD;">PATH</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$</span><span style="color:#C678DD;--shiki-dark:#C678DD;">PATH</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">:$KE_HOME/bin</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 注意：source /etc/profile</span></span></code></pre></div><ol start="9"><li>启动</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#E06C75;--shiki-dark:#E06C75;">[atguigu@hadoop102 eagle]</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">$ bin/</span><span style="color:#D19A66;--shiki-dark:#D19A66;">ke</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> start</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">... ...</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">... ...</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">*******************************************************************</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">* Kafka Eagle </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Service</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> has </span><span style="color:#C678DD;--shiki-dark:#C678DD;">started</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> success.</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">* Welcome, </span><span style="color:#C678DD;--shiki-dark:#C678DD;">Now</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> you can visit </span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;http://192.168.9.102:8048/ke&#39;</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> -- 这个网址就是登入的eagle的网址</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">* Account:</span><span style="color:#C678DD;--shiki-dark:#C678DD;">admin</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ,</span><span style="color:#C678DD;--shiki-dark:#C678DD;">Password</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">123456</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> -- 这是登入的密码</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">*******************************************************************</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">* </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">Usage</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> ke</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sh</span><span style="color:#E06C75;--shiki-dark:#E06C75;"> [start|status|stop|restart|stats]</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> &lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/Usage</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">* </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">Usage</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> https://</span><span style="color:#D19A66;--shiki-dark:#D19A66;">www</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">-</span><span style="color:#D19A66;--shiki-dark:#D19A66;">eagle</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">org</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/ </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&lt;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/Usage</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">*******************************************************************</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--注意：启动之前需要先启动ZK以及KAFKA</span></span></code></pre></div><ol start="10"><li>登录页面查看监控数据</li></ol><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">网址： </span><span style="color:#C678DD;--shiki-dark:#C678DD;">http</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">://</span><span style="color:#D19A66;--shiki-dark:#D19A66;">192</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">168</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">102</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">8048</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">/ke</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">账号： </span><span style="color:#C678DD;--shiki-dark:#C678DD;">admin</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">密码： </span><span style="color:#D19A66;--shiki-dark:#D19A66;">123456</span></span></code></pre></div><h2 id="六、面试题" tabindex="-1"><a class="header-anchor" href="#六、面试题"><span>六、面试题</span></a></h2><h3 id="_6-1-kafka中的isr、ar代表什么" tabindex="-1"><a class="header-anchor" href="#_6-1-kafka中的isr、ar代表什么"><span>6.1 Kafka中的ISR、AR代表什么</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">ISR:分区leader维护的一个follower列表，在isr中的follower与leader同步。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">AR:分区的所有副本。</span></span></code></pre></div><h3 id="_6-2-kafka中的hw、leo等分别代表什么" tabindex="-1"><a class="header-anchor" href="#_6-2-kafka中的hw、leo等分别代表什么"><span>6.2 Kafka中的HW、LEO等分别代表什么</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">LEO: leader维护的isr中所有follower的最后偏移量。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">HW：所有followerleo最小的值。</span></span></code></pre></div><h3 id="_6-3-kafka中是怎么体现消息顺序性的" tabindex="-1"><a class="header-anchor" href="#_6-3-kafka中是怎么体现消息顺序性的"><span>6.3 Kafka中是怎么体现消息顺序性的</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">每次生产的数据是在一个上次生产数据的基础上追加，同时存储了消息的offset和数据的index索引，减少了数据存储时的磁头寻址的过程。</span></span></code></pre></div><h3 id="_6-4-kafka中的分区器、序列化器、拦截器是否了解-它们之间的处理顺序是什么" tabindex="-1"><a class="header-anchor" href="#_6-4-kafka中的分区器、序列化器、拦截器是否了解-它们之间的处理顺序是什么"><span>6.4 Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">处理顺序： 拦截器 </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--&gt; 序列化器 --&gt; 分区器</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">拦截器：对数据进行简单处理，加一些标识。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">序列化：对数据进行序列化，保证数据可用于传输；</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">分区器：给数据加上分区标签，指定数据应该去到哪个kafka集群中的分区。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">以上三步骤均在producer端就完成了。</span></span></code></pre></div><h3 id="_6-5-kafka生产者客户端的整体结构是什么样子的-使用了几个线程来处理-分别是什么" tabindex="-1"><a class="header-anchor" href="#_6-5-kafka生产者客户端的整体结构是什么样子的-使用了几个线程来处理-分别是什么"><span>6.5 Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>一共2个线程，一个数据缓存区。</span></span>
<span class="line"><span>线程</span></span>
<span class="line"><span>main线程：负责对数据进行包装、序列化、分区。</span></span>
<span class="line"><span>sender线程：负责将数据从数据缓冲区发送topic话题中。</span></span></code></pre></div><h3 id="_6-6-消费者组中的消费者个数如果超过topic的分区-那么就会有消费者消费不到数据这句话是否正确" tabindex="-1"><a class="header-anchor" href="#_6-6-消费者组中的消费者个数如果超过topic的分区-那么就会有消费者消费不到数据这句话是否正确"><span>6.6 消费者组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据这句话是否正确</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>是的，正确。</span></span>
<span class="line"><span>了解一下分区分配的策略。</span></span>
<span class="line"><span>三种方式：roundrobin 、 range  、sticky。</span></span></code></pre></div><h3 id="_6-7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1" tabindex="-1"><a class="header-anchor" href="#_6-7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1"><span>6.7 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>offset + 1 。</span></span></code></pre></div><h3 id="_6-8-有哪些情形会造成重复消费" tabindex="-1"><a class="header-anchor" href="#_6-8-有哪些情形会造成重复消费"><span>6.8 有哪些情形会造成重复消费？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>先消费后提交offset。</span></span></code></pre></div><h3 id="_6-9-那些情景会造成消息漏消费" tabindex="-1"><a class="header-anchor" href="#_6-9-那些情景会造成消息漏消费"><span>6.9 那些情景会造成消息漏消费？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>先提交offset后消费。</span></span></code></pre></div><h3 id="_6-10-当你使用kafka-topics-sh创建-删除-了一个topic之后-kafka背后会执行什么逻辑" tabindex="-1"><a class="header-anchor" href="#_6-10-当你使用kafka-topics-sh创建-删除-了一个topic之后-kafka背后会执行什么逻辑"><span>6.10 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>了解producer发送数据的过程。</span></span></code></pre></div><h3 id="_6-11-topic的分区数可不可以增加-如果可以怎么增加-如果不可以-那又是为什么" tabindex="-1"><a class="header-anchor" href="#_6-11-topic的分区数可不可以增加-如果可以怎么增加-如果不可以-那又是为什么"><span>6.11 topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>可以增加。</span></span></code></pre></div><h3 id="_6-12-topic的分区数可不可以减少-如果可以怎么减少-如果不可以-那又是为什么" tabindex="-1"><a class="header-anchor" href="#_6-12-topic的分区数可不可以减少-如果可以怎么减少-如果不可以-那又是为什么"><span>6.12 topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>不能减少，因为原分区中的数据没有地方去。</span></span></code></pre></div><h3 id="_6-13-kafka有内部的topic吗-如果有是什么-有什么作用" tabindex="-1"><a class="header-anchor" href="#_6-13-kafka有内部的topic吗-如果有是什么-有什么作用"><span>6.13 Kafka有内部的topic吗？如果有是什么？有什么作用？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span></span></span>
<span class="line"><span>会话：_consumer_offset，保存consumer消费的偏移量。</span></span></code></pre></div><h3 id="_6-14-kafka分区分配的概念" tabindex="-1"><a class="header-anchor" href="#_6-14-kafka分区分配的概念"><span>6.14 Kafka分区分配的概念？</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">一共有三种分区分配的策略。</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">三种方式：</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）roundrobin ： 轮询分配。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）</span><span style="color:#C678DD;--shiki-dark:#C678DD;">range</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> ： 平均分配。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）sticky ： 轮询分配 + 解决新增消费者的优化。</span></span></code></pre></div><h3 id="_6-15-简述kafka的日志目录结构" tabindex="-1"><a class="header-anchor" href="#_6-15-简述kafka的日志目录结构"><span>6.15 简述Kafka的日志目录结构？</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">一共有3个文件</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）log文件：记录真实数据，内部包含了真实数据 + hw + leo。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">2</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">）index文件 ： 存储消息的偏移量。</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) timeindex文件 ： 存储下消息的时间偏移量。</span></span></code></pre></div><h3 id="_6-16-如果我指定了一个offset-kafka-controller怎么查找到对应的消息" tabindex="-1"><a class="header-anchor" href="#_6-16-如果我指定了一个offset-kafka-controller怎么查找到对应的消息"><span>6.16 如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>通过offset，消息的偏移量，通过日志目录的文件顺序号，根据区间范围找到消息所在的inde和log目录。</span></span>
<span class="line"><span>其次根据在index表中的消息偏移量找到真实数据在log文件中该消息的起始索引位置。</span></span></code></pre></div><h3 id="_6-17聊一聊kafka-controller的作用" tabindex="-1"><a class="header-anchor" href="#_6-17聊一聊kafka-controller的作用"><span>6.17聊一聊Kafka Controller的作用？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>1、负责leader的选举；</span></span>
<span class="line"><span>2、负责监控leader的状态；</span></span>
<span class="line"><span>3.负责更新集群在zookeeper中的状态。</span></span></code></pre></div><h3 id="_6-18-kafka中有那些地方需要选举-这些地方的选举策略又有哪些" tabindex="-1"><a class="header-anchor" href="#_6-18-kafka中有那些地方需要选举-这些地方的选举策略又有哪些"><span>6.18 Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>1.每个分区的leader选举；(isr)；</span></span>
<span class="line"><span>2.controller的选举（先到先得）。</span></span></code></pre></div><h3 id="_6-19-失效副本是指什么-有那些应对措施" tabindex="-1"><a class="header-anchor" href="#_6-19-失效副本是指什么-有那些应对措施"><span>6.19 失效副本是指什么？有那些应对措施？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>follower不能与leader进行同步数据，暂时被leader踢出isr列表中。通过followe故障恢复重新备份，当leo达到了isr中的hw时，又重新会回到isr的列表中。</span></span></code></pre></div><h3 id="_6-20-kafka的那些设计让它有如此高的性能" tabindex="-1"><a class="header-anchor" href="#_6-20-kafka的那些设计让它有如此高的性能"><span>6.20 Kafka的那些设计让它有如此高的性能？</span></a></h3><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>1. pagecache；</span></span>
<span class="line"><span>2.顺序读写机制；</span></span>
<span class="line"><span>3.零拷贝技术；</span></span>
<span class="line"><span>4.多分区策略。</span></span></code></pre></div><h2 id="七-、flume与kafka融合技术" tabindex="-1"><a class="header-anchor" href="#七-、flume与kafka融合技术"><span>七 、flume与kafka融合技术</span></a></h2><p>kafka：数据的中转站，主要功能由topic体现；</p><p>flume：数据的采集，通过source和sink体现。</p><h3 id="_7-1-kafka-source" tabindex="-1"><a class="header-anchor" href="#_7-1-kafka-source"><span>7.1 kafka source</span></a></h3><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 问题 ：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">fulme在kafka中的作用</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 答案：</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">消费者</span></span></code></pre></div><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sources</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">r1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">type</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> org</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">apache</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">flume</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">source</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">KafkaSource</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --source类型</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sources</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">r1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">bootstrap</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">servers</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> hadoop105:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop106:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> -- kafka的集群</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sources</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">r1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.topics</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">topic_log </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 订阅的话题</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sources</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">r1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">batchSize</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">6000</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --putlist中数据达到了6K以后提交到channel中</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sources</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">r1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">batchDurationMillis</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">2000</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --拉取数据的时间达到2s以后，将获取的数据提交到channel中</span></span></code></pre></div><h3 id="_7-2-kakfa-channel" tabindex="-1"><a class="header-anchor" href="#_7-2-kakfa-channel"><span>7.2 kakfa channel</span></a></h3><ul><li>kakfa channel这种情况使用的最多，此时的flume可以是消费者、生产者、source和sink之间的缓冲区（具有高吞吐量的优势），Channel是位于Source和Sink之间的缓冲区。</li><li>一共有三种情况，分别是:</li></ul><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 情况一： 有Flume source and sink -- 缓冲区</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">kakfa channel为事件提供了可靠且高可用的通道；</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 情况二： 有source and interceptor but no sink --生产者</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">it allows writing Flume events </span><span style="color:#C678DD;--shiki-dark:#C678DD;">into</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> a Kafka topic, </span><span style="color:#C678DD;--shiki-dark:#C678DD;">for</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> use</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> by</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> other app</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 情况三： 有 sink, but no source --消费者</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">it </span><span style="color:#C678DD;--shiki-dark:#C678DD;">is</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> a low-latency, fault tolerant way </span><span style="color:#C678DD;--shiki-dark:#C678DD;">to</span><span style="color:#C678DD;--shiki-dark:#C678DD;"> send</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> events </span><span style="color:#C678DD;--shiki-dark:#C678DD;">from</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Kafka </span><span style="color:#C678DD;--shiki-dark:#C678DD;">to</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Flume sinks such </span><span style="color:#C678DD;--shiki-dark:#C678DD;">as</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> HDFS, HBase </span><span style="color:#C678DD;--shiki-dark:#C678DD;">or</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> Solr</span></span></code></pre></div><p>官方配置文件：</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">channels</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">c1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">type</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> org</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">apache</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">flume</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">channel</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">KafkaChannel</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> ----channel类型</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">channels</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">c1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">bootstrap</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">servers</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> hadoop105:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop106:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop107:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --kafka集群</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">channels</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">c1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.topic </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">topic_log </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--话题</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">channels</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">c1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">parseAsFlumeEvent</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">false </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--不需要event的header数据</span></span></code></pre></div><h3 id="_7-3-kafka-sink" tabindex="-1"><a class="header-anchor" href="#_7-3-kafka-sink"><span>7.3 kafka sink</span></a></h3><p>作用：将数据拉去到kafka的topic中。</p><div class="language-sql" data-ext="sql" data-title="sql"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">type</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> org</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">apache</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">flume</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sink</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">KafkaSink</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --sink类型</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.topic </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">topic_log </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--话题</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">bootstrap</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">servers</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> hadoop105:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop106:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">,hadoop107:</span><span style="color:#D19A66;--shiki-dark:#D19A66;">9092</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --kafka集群</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.flumeBatchSize </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 20</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">acks</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 1</span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> --副本策略</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">linger</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.ms </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">a1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">sinks</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">k1</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">kafka</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">producer</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#D19A66;--shiki-dark:#D19A66;">compression</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">.</span><span style="color:#C678DD;--shiki-dark:#C678DD;">type</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> snappy  </span><span style="color:#7F848E;font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--压缩格式</span></span></code></pre></div>`,239)]))}const k=a(e,[["render",r],["__file","Kafka总结.html.vue"]]),B=JSON.parse('{"path":"/posts/BigData/06_Kafka%E6%80%BB%E7%BB%93/Kafka%E6%80%BB%E7%BB%93.html","title":"Kafka总结","lang":"zh-CN","frontmatter":{"description":"Kafka总结 一、kafka概述 1.1 kafka定义 Kafka是一个分布式的基于发布/订阅模式的消息队列，主要应用于大数据实时处理领域。 订阅式模式：一对多的关系，一个生产者，数据存储在消息队列中，多个消费者均可从这个消息对列中获取数据，消费者消费数据之后不会清除消息。 1.2 框架说明 一般都是从命令行和API两个方面进行讲解。 数据处理框架...","head":[["meta",{"property":"og:url","content":"https://springg.us.kg/posts/BigData/06_Kafka%E6%80%BB%E7%BB%93/Kafka%E6%80%BB%E7%BB%93.html"}],["meta",{"property":"og:site_name","content":"mrjason’s Blog"}],["meta",{"property":"og:title","content":"Kafka总结"}],["meta",{"property":"og:description","content":"Kafka总结 一、kafka概述 1.1 kafka定义 Kafka是一个分布式的基于发布/订阅模式的消息队列，主要应用于大数据实时处理领域。 订阅式模式：一对多的关系，一个生产者，数据存储在消息队列中，多个消费者均可从这个消息对列中获取数据，消费者消费数据之后不会清除消息。 1.2 框架说明 一般都是从命令行和API两个方面进行讲解。 数据处理框架..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005434.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-28T01:58:08.000Z"}],["meta",{"property":"article:author","content":"MrJason"}],["meta",{"property":"article:modified_time","content":"2024-10-28T01:58:08.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka总结\\",\\"image\\":[\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005434.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200610151457.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200714205928.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200714210619.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005453.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005450.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005509.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005514.png\\",\\"https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200529005518.png\\"],\\"dateModified\\":\\"2024-10-28T01:58:08.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"MrJason\\",\\"url\\":\\"https://springg.us.kg\\"}]}"]]},"headers":[{"level":2,"title":"一、kafka概述","slug":"一、kafka概述","link":"#一、kafka概述","children":[{"level":3,"title":"1.1 kafka定义","slug":"_1-1-kafka定义","link":"#_1-1-kafka定义","children":[]},{"level":3,"title":"1.2 框架说明","slug":"_1-2-框架说明","link":"#_1-2-框架说明","children":[]},{"level":3,"title":"1.3 Kafka涉及的关键词","slug":"_1-3-kafka涉及的关键词","link":"#_1-3-kafka涉及的关键词","children":[]}]},{"level":2,"title":"二、Kafka安装","slug":"二、kafka安装","link":"#二、kafka安装","children":[{"level":3,"title":"2.1 集群部署","slug":"_2-1-集群部署","link":"#_2-1-集群部署","children":[]},{"level":3,"title":"2.2 Kafka命令操作","slug":"_2-2-kafka命令操作","link":"#_2-2-kafka命令操作","children":[]}]},{"level":2,"title":"三、 Kafka深入流程","slug":"三、-kafka深入流程","link":"#三、-kafka深入流程","children":[{"level":3,"title":"3.1 Kafka工作流程及文件存储机制","slug":"_3-1-kafka工作流程及文件存储机制","link":"#_3-1-kafka工作流程及文件存储机制","children":[]},{"level":3,"title":"3.2 Kafka之生产者producer","slug":"_3-2-kafka之生产者producer","link":"#_3-2-kafka之生产者producer","children":[]},{"level":3,"title":"3.3 Kafka之消费者 consumer","slug":"_3-3-kafka之消费者-consumer","link":"#_3-3-kafka之消费者-consumer","children":[]},{"level":3,"title":"3.4  Kafka高效读写数据","slug":"_3-4-kafka高效读写数据","link":"#_3-4-kafka高效读写数据","children":[]},{"level":3,"title":"3.5  zookeeper在kafka中的作用","slug":"_3-5-zookeeper在kafka中的作用","link":"#_3-5-zookeeper在kafka中的作用","children":[]},{"level":3,"title":"3.6 Kafka事务","slug":"_3-6-kafka事务","link":"#_3-6-kafka事务","children":[]}]},{"level":2,"title":"四、 Kafka API","slug":"四、-kafka-api","link":"#四、-kafka-api","children":[{"level":3,"title":"4.1 Producer API","slug":"_4-1-producer-api","link":"#_4-1-producer-api","children":[]},{"level":3,"title":"4.2  Consumer API","slug":"_4-2-consumer-api","link":"#_4-2-consumer-api","children":[]}]},{"level":2,"title":"五、Kafka监控（Kafka Eagle）","slug":"五、kafka监控-kafka-eagle","link":"#五、kafka监控-kafka-eagle","children":[]},{"level":2,"title":"六、面试题","slug":"六、面试题","link":"#六、面试题","children":[{"level":3,"title":"6.1  Kafka中的ISR、AR代表什么","slug":"_6-1-kafka中的isr、ar代表什么","link":"#_6-1-kafka中的isr、ar代表什么","children":[]},{"level":3,"title":"6.2 Kafka中的HW、LEO等分别代表什么","slug":"_6-2-kafka中的hw、leo等分别代表什么","link":"#_6-2-kafka中的hw、leo等分别代表什么","children":[]},{"level":3,"title":"6.3 Kafka中是怎么体现消息顺序性的","slug":"_6-3-kafka中是怎么体现消息顺序性的","link":"#_6-3-kafka中是怎么体现消息顺序性的","children":[]},{"level":3,"title":"6.4 Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？","slug":"_6-4-kafka中的分区器、序列化器、拦截器是否了解-它们之间的处理顺序是什么","link":"#_6-4-kafka中的分区器、序列化器、拦截器是否了解-它们之间的处理顺序是什么","children":[]},{"level":3,"title":"6.5  Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？","slug":"_6-5-kafka生产者客户端的整体结构是什么样子的-使用了几个线程来处理-分别是什么","link":"#_6-5-kafka生产者客户端的整体结构是什么样子的-使用了几个线程来处理-分别是什么","children":[]},{"level":3,"title":"6.6 消费者组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据这句话是否正确","slug":"_6-6-消费者组中的消费者个数如果超过topic的分区-那么就会有消费者消费不到数据这句话是否正确","link":"#_6-6-消费者组中的消费者个数如果超过topic的分区-那么就会有消费者消费不到数据这句话是否正确","children":[]},{"level":3,"title":"6.7 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？","slug":"_6-7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1","link":"#_6-7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1","children":[]},{"level":3,"title":"6.8 有哪些情形会造成重复消费？","slug":"_6-8-有哪些情形会造成重复消费","link":"#_6-8-有哪些情形会造成重复消费","children":[]},{"level":3,"title":"6.9 那些情景会造成消息漏消费？","slug":"_6-9-那些情景会造成消息漏消费","link":"#_6-9-那些情景会造成消息漏消费","children":[]},{"level":3,"title":"6.10 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？","slug":"_6-10-当你使用kafka-topics-sh创建-删除-了一个topic之后-kafka背后会执行什么逻辑","link":"#_6-10-当你使用kafka-topics-sh创建-删除-了一个topic之后-kafka背后会执行什么逻辑","children":[]},{"level":3,"title":"6.11 topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？","slug":"_6-11-topic的分区数可不可以增加-如果可以怎么增加-如果不可以-那又是为什么","link":"#_6-11-topic的分区数可不可以增加-如果可以怎么增加-如果不可以-那又是为什么","children":[]},{"level":3,"title":"6.12 topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？","slug":"_6-12-topic的分区数可不可以减少-如果可以怎么减少-如果不可以-那又是为什么","link":"#_6-12-topic的分区数可不可以减少-如果可以怎么减少-如果不可以-那又是为什么","children":[]},{"level":3,"title":"6.13 Kafka有内部的topic吗？如果有是什么？有什么作用？","slug":"_6-13-kafka有内部的topic吗-如果有是什么-有什么作用","link":"#_6-13-kafka有内部的topic吗-如果有是什么-有什么作用","children":[]},{"level":3,"title":"6.14 Kafka分区分配的概念？","slug":"_6-14-kafka分区分配的概念","link":"#_6-14-kafka分区分配的概念","children":[]},{"level":3,"title":"6.15 简述Kafka的日志目录结构？","slug":"_6-15-简述kafka的日志目录结构","link":"#_6-15-简述kafka的日志目录结构","children":[]},{"level":3,"title":"6.16 如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？","slug":"_6-16-如果我指定了一个offset-kafka-controller怎么查找到对应的消息","link":"#_6-16-如果我指定了一个offset-kafka-controller怎么查找到对应的消息","children":[]},{"level":3,"title":"6.17聊一聊Kafka Controller的作用？","slug":"_6-17聊一聊kafka-controller的作用","link":"#_6-17聊一聊kafka-controller的作用","children":[]},{"level":3,"title":"6.18  Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？","slug":"_6-18-kafka中有那些地方需要选举-这些地方的选举策略又有哪些","link":"#_6-18-kafka中有那些地方需要选举-这些地方的选举策略又有哪些","children":[]},{"level":3,"title":"6.19  失效副本是指什么？有那些应对措施？","slug":"_6-19-失效副本是指什么-有那些应对措施","link":"#_6-19-失效副本是指什么-有那些应对措施","children":[]},{"level":3,"title":"6.20  Kafka的那些设计让它有如此高的性能？","slug":"_6-20-kafka的那些设计让它有如此高的性能","link":"#_6-20-kafka的那些设计让它有如此高的性能","children":[]}]},{"level":2,"title":"七 、flume与kafka融合技术","slug":"七-、flume与kafka融合技术","link":"#七-、flume与kafka融合技术","children":[{"level":3,"title":"7.1 kafka source","slug":"_7-1-kafka-source","link":"#_7-1-kafka-source","children":[]},{"level":3,"title":"7.2 kakfa channel","slug":"_7-2-kakfa-channel","link":"#_7-2-kakfa-channel","children":[]},{"level":3,"title":"7.3 kafka sink","slug":"_7-3-kafka-sink","link":"#_7-3-kafka-sink","children":[]}]}],"git":{"createdTime":1730080688000,"updatedTime":1730080688000,"contributors":[{"name":"MrJason","email":"845886914@qq.com","commits":1}]},"readingTime":{"minutes":31.46,"words":9437},"filePathRelative":"posts/BigData/06_Kafka总结/Kafka总结.md","localizedDate":"2024年10月28日","excerpt":"\\n<hr>\\n<h2>一、kafka概述</h2>\\n<h3>1.1 kafka定义</h3>\\n<blockquote>\\n<p>Kafka是一个分布式的基于<strong>发布/订阅</strong>模式的<strong>消息队列，<strong>主要应用于大数据</strong>实时</strong>处理领域。</p>\\n<p>订阅式模式：一对多的关系，一个生产者，数据存储在消息队列中，多个消费者均可从这个消息对列中获取数据，<strong>消费者消费数据之后不会清除消息。</strong></p>\\n</blockquote>\\n<h3>1.2 框架说明</h3>\\n<blockquote>\\n<p>一般都是从命令行和API两个方面进行讲解。</p>\\n<p>数据处理框架需要从数据的安全性以及效率两个方面深入了解。</p>\\n</blockquote>","autoDesc":true}');export{k as comp,B as data};
