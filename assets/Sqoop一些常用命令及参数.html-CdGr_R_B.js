import{_ as t,c as a,a as n,o as d}from"./app-DP7tPpgD.js";const e={};function r(o,s){return d(),a("div",null,s[0]||(s[0]=[n(`<h1 id="sqoop一些常用命令及参数" tabindex="-1"><a class="header-anchor" href="#sqoop一些常用命令及参数"><span><strong>Sqoop</strong>一些常用命令及参数</span></a></h1><h2 id="_5-1-常用命令列举" tabindex="-1"><a class="header-anchor" href="#_5-1-常用命令列举"><span><strong>5.1</strong> <strong>常用命令列举</strong></span></a></h2><table><thead><tr><th><strong>序号</strong></th><th><strong>命令</strong></th><th><strong>类</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>import</td><td>ImportTool</td><td>将数据导入到集群</td></tr><tr><td>2</td><td>export</td><td>ExportTool</td><td>将集群数据导出</td></tr><tr><td>3</td><td>codegen</td><td>CodeGenTool</td><td>获取数据库中某张表数据生成Java并打包Jar</td></tr><tr><td>4</td><td>create-hive-table</td><td>CreateHiveTableTool</td><td>创建Hive表</td></tr><tr><td>5</td><td>eval</td><td>EvalSqlTool</td><td>查看SQL执行结果</td></tr><tr><td>6</td><td>import-all-tables</td><td>ImportAllTablesTool</td><td>导入某个数据库下所有表到HDFS中</td></tr><tr><td>7</td><td>job</td><td>JobTool</td><td>用来生成一个sqoop的任务，生成后，该任务并不执行，除非使用命令执行该任务。</td></tr><tr><td>8</td><td>list-databases</td><td>ListDatabasesTool</td><td>列出所有数据库名</td></tr><tr><td>9</td><td>list-tables</td><td>ListTablesTool</td><td>列出某个数据库下所有表</td></tr><tr><td>10</td><td>merge</td><td>MergeTool</td><td>将HDFS中不同目录下面的数据合在一起，并存放在指定的目录中</td></tr><tr><td>11</td><td>metastore</td><td>MetastoreTool</td><td>记录sqoop job的元数据信息，如果不启动metastore实例，则默认的元数据存储目录为：~/.sqoop，如果要更改存储目录，可以在配置文件sqoop-site.xml中进行更改。</td></tr><tr><td>12</td><td>help</td><td>HelpTool</td><td>打印sqoop帮助信息</td></tr><tr><td>13</td><td>version</td><td>VersionTool</td><td>打印sqoop版本信息</td></tr></tbody></table><h2 id="_5-2-命令-参数详解" tabindex="-1"><a class="header-anchor" href="#_5-2-命令-参数详解"><span><strong>5.2</strong> <strong>命令</strong>&amp;参数详解</span></a></h2><p>刚才列举了一些Sqoop的常用命令，对于不同的命令，有不同的参数，让我们来一一列举说明。</p><p>首先来我们来介绍一下公用的参数，所谓公用参数，就是大多数命令都支持的参数。</p><h3 id="_5-2-1-公用参数-数据库连接" tabindex="-1"><a class="header-anchor" href="#_5-2-1-公用参数-数据库连接"><span><strong>5.2.1</strong> <strong>公用参数：数据库连接</strong></span></a></h3><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--connect</td><td>连接关系型数据库的URL</td></tr><tr><td>2</td><td>--connection-manager</td><td>指定要使用的连接管理类</td></tr><tr><td>3</td><td>--driver</td><td>Hadoop根目录</td></tr><tr><td>4</td><td>--help</td><td>打印帮助信息</td></tr><tr><td>5</td><td>--password</td><td>连接数据库的密码</td></tr><tr><td>6</td><td>--username</td><td>连接数据库的用户名</td></tr><tr><td>7</td><td>--verbose</td><td>在控制台打印出详细信息</td></tr></tbody></table><h3 id="_5-2-2-公用参数-import" tabindex="-1"><a class="header-anchor" href="#_5-2-2-公用参数-import"><span><strong>5.2.2</strong> **公用参数：**import</span></a></h3><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--enclosed-by <code>&lt;char&gt;</code></td><td>给字段值前加上指定的字符</td></tr><tr><td>2</td><td>--escaped-by <code>&lt;char&gt;</code></td><td>对字段中的双引号加转义符</td></tr><tr><td>3</td><td>--fields-terminated-by <code>&lt;char&gt;</code></td><td>设定每个字段是以什么符号作为结束，默认为逗号</td></tr><tr><td>4</td><td>--lines-terminated-by <code>&lt;char&gt;</code></td><td>设定每行记录之间的分隔符，默认是\\n</td></tr><tr><td>5</td><td>--mysql-delimiters</td><td>Mysql默认的分隔符设置，字段之间以逗号分隔，行之间以\\n分隔，默认转义符是\\，字段值以单引号包裹。</td></tr><tr><td>6</td><td>--optionally-enclosed-by <code>&lt;char&gt;</code></td><td>给带有双引号或单引号的字段值前后加上指定字符。</td></tr></tbody></table><h3 id="_5-2-3-公用参数-export" tabindex="-1"><a class="header-anchor" href="#_5-2-3-公用参数-export"><span><strong>5.2.3</strong> **公用参数：**export</span></a></h3><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--input-enclosed-by <code>&lt;char&gt;</code></td><td>对字段值前后加上指定字符</td></tr><tr><td>2</td><td>--input-escaped-by <code>&lt;char&gt;</code></td><td>对含有转移符的字段做转义处理</td></tr><tr><td>3</td><td>--input-fields-terminated-by <code>&lt;char&gt;</code></td><td>字段之间的分隔符</td></tr><tr><td>4</td><td>--input-lines-terminated-by <code>&lt;char&gt;</code></td><td>行之间的分隔符</td></tr><tr><td>5</td><td>--input-optionally-enclosed-by <code>&lt;char&gt;</code></td><td>给带有双引号或单引号的字段前后加上指定字符</td></tr></tbody></table><h3 id="_5-2-4-公用参数-hive" tabindex="-1"><a class="header-anchor" href="#_5-2-4-公用参数-hive"><span><strong>5.2.4</strong> **公用参数：**hive</span></a></h3><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--hive-delims-replacement <code>&lt;arg&gt;</code></td><td>用自定义的字符串替换掉数据中的\\r\\n和\\013 \\010等字符</td></tr><tr><td>2</td><td>--hive-drop-import-delims</td><td>在导入数据到hive时，去掉数据中的\\r\\n\\013\\010这样的字符</td></tr><tr><td>3</td><td>--map-column-hive <code>&lt;arg&gt;</code></td><td>生成hive表时，可以更改生成字段的数据类型</td></tr><tr><td>4</td><td>--hive-partition-key</td><td>创建分区，后面直接跟分区名，分区字段的默认类型为string</td></tr><tr><td>5</td><td>--hive-partition-value <code>&lt;v&gt;</code></td><td>导入数据时，指定某个分区的值</td></tr><tr><td>6</td><td>--hive-home <code>&lt;dir&gt;</code></td><td>hive的安装目录，可以通过该参数覆盖之前默认配置的目录</td></tr><tr><td>7</td><td>--hive-import</td><td>将数据从关系数据库中导入到hive表中</td></tr><tr><td>8</td><td>--hive-overwrite</td><td>覆盖掉在hive表中已经存在的数据</td></tr><tr><td>9</td><td>--create-hive-table</td><td>默认是false，即，如果目标表已经存在了，那么创建任务失败。</td></tr><tr><td>10</td><td>--hive-table</td><td>后面接要创建的hive表,默认使用MySQL的表名</td></tr><tr><td>11</td><td>--table</td><td>指定关系数据库的表名</td></tr></tbody></table><p>公用参数介绍完之后，我们来按照命令介绍命令对应的特有参数。</p><h3 id="_5-2-5-命令-参数-import" tabindex="-1"><a class="header-anchor" href="#_5-2-5-命令-参数-import"><span><strong>5.2.5</strong> <strong>命令</strong>&amp;参数：import</span></a></h3><p>将关系型数据库中的数据导入到HDFS（包括Hive，HBase）中，如果导入的是Hive，那么当Hive中没有对应表时，则自动创建。</p><p><strong>1)</strong> <strong>命令：</strong></p><p>如：导入数据到hive中</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> import</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--hive-import</span></span></code></pre></div><p>如：增量导入数据到hive中，mode=append</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">append导入：</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> import</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--num-mappers </span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--fields-terminated-by </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;\\t&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--target-dir </span><span style="color:#98C379;--shiki-dark:#98C379;">/user/hive/warehouse/staff_hive</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--check-column </span><span style="color:#98C379;--shiki-dark:#98C379;">id</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--incremental </span><span style="color:#98C379;--shiki-dark:#98C379;">append</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--last-value </span><span style="color:#D19A66;--shiki-dark:#D19A66;">3</span></span></code></pre></div><p>提示：append不能与--hive-等参数同时使用（Append mode for hive imports is not yet supported. Please remove the parameter --append-mode）</p><p>如：增量导入数据到hdfs中，mode=lastmodified</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">先在mysql中建表并插入几条数据：</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">mysql</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span><span style="color:#98C379;--shiki-dark:#98C379;">\` </span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">create</span><span style="color:#98C379;--shiki-dark:#98C379;"> table company.staff_timestamp(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">id</span><span style="color:#98C379;--shiki-dark:#98C379;"> int(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">4</span><span style="color:#98C379;--shiki-dark:#98C379;">), name varchar(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">255</span><span style="color:#98C379;--shiki-dark:#98C379;">), sex varchar(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">255</span><span style="color:#98C379;--shiki-dark:#98C379;">), last_modified timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP);</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">mysql</span><span style="color:#98C379;--shiki-dark:#98C379;">&gt;\`</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> insert</span><span style="color:#98C379;--shiki-dark:#98C379;"> into</span><span style="color:#98C379;--shiki-dark:#98C379;"> company.staff_timestamp</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (id, </span><span style="color:#98C379;--shiki-dark:#98C379;">name,</span><span style="color:#98C379;--shiki-dark:#98C379;"> sex</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) values(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">1,</span><span style="color:#98C379;--shiki-dark:#98C379;"> &#39;AAA&#39;,</span><span style="color:#98C379;--shiki-dark:#98C379;"> &#39;female&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">mysql</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;</span><span style="color:#98C379;--shiki-dark:#98C379;">\` </span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">insert</span><span style="color:#98C379;--shiki-dark:#98C379;"> into company.staff_timestamp (id, name, sex) values(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">2,</span><span style="color:#98C379;--shiki-dark:#98C379;"> &#39;BBB&#39;, &#39;female&#39;);</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">先导入一部分数据：</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop import </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">--connect jdbc:mysql://hadoop102:3306/company </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">--username root </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">--table staff_timestamp </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">--delete-target-dir </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">\\</span></span>
<span class="line"><span style="color:#98C379;--shiki-dark:#98C379;">--m </span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">再增量导入一部分数据：</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">mysql</span><span style="color:#98C379;--shiki-dark:#98C379;">&gt;\`</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;"> insert</span><span style="color:#98C379;--shiki-dark:#98C379;"> into</span><span style="color:#98C379;--shiki-dark:#98C379;"> company.staff_timestamp</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> (id, </span><span style="color:#98C379;--shiki-dark:#98C379;">name,</span><span style="color:#98C379;--shiki-dark:#98C379;"> sex</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">) values(</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">3,</span><span style="color:#98C379;--shiki-dark:#98C379;"> &#39;CCC&#39;,</span><span style="color:#98C379;--shiki-dark:#98C379;"> &#39;female&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> import</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff_timestamp</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--check-column </span><span style="color:#98C379;--shiki-dark:#98C379;">last_modified</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--incremental </span><span style="color:#98C379;--shiki-dark:#98C379;">lastmodified</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--last-value </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;2017-09-28 22:20:38&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--m </span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--append</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>尖叫提示：使用lastmodified方式导入数据要指定增量数据是要--append（追加）还是要--merge-key（合并）</p><p>尖叫提示：last-value指定的值是会包含于增量导入的数据中</p><p><strong>2)</strong> <strong>参数：</strong></p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--append</td><td>将数据追加到HDFS中已经存在的DataSet中，如果使用该参数，sqoop会把数据先导入到临时文件目录，再合并。</td></tr><tr><td>2</td><td>--as-avrodatafile</td><td>将数据导入到一个Avro数据文件中</td></tr><tr><td>3</td><td>--as-sequencefile</td><td>将数据导入到一个sequence文件中</td></tr><tr><td>4</td><td>--as-textfile</td><td>将数据导入到一个普通文本文件中</td></tr><tr><td>5</td><td>--boundary-query <code>&lt;statement&gt;</code></td><td>边界查询，导入的数据为该参数的值（一条sql语句）所执行的结果区间内的数据。</td></tr><tr><td>6</td><td>--columns <code>&lt;col1, col2, col3&gt;</code></td><td>指定要导入的字段</td></tr><tr><td>7</td><td>--direct</td><td>直接导入模式，使用的是关系数据库自带的导入导出工具，以便加快导入导出过程。</td></tr><tr><td>8</td><td>--direct-split-size</td><td>在使用上面direct直接导入的基础上，对导入的流按字节分块，即达到该阈值就产生一个新的文件</td></tr><tr><td>9</td><td>--inline-lob-limit</td><td>设定大对象数据类型的最大值</td></tr><tr><td>10</td><td>--m或–num-mappers</td><td>启动N个map来并行导入数据，默认4个。</td></tr><tr><td>11</td><td>--query或--e <code>&lt;statement&gt;</code></td><td>将查询结果的数据导入，使用时必须伴随参--target-dir，--hive-table，如果查询中有where条件，则条件后必须加上$CONDITIONS关键字</td></tr><tr><td>12</td><td>--split-by <code>&lt;column-name&gt;</code></td><td>按照某一列来切分表的工作单元，不能与--autoreset-to-one-mapper连用（请参考官方文档）</td></tr><tr><td>13</td><td>--table <code>&lt;table-name&gt;</code></td><td>关系数据库的表名</td></tr><tr><td>14</td><td>--target-dir <code>&lt;dir&gt;</code></td><td>指定HDFS路径</td></tr><tr><td>15</td><td>--warehouse-dir <code>&lt;dir&gt;</code></td><td>与14参数不能同时使用，导入数据到HDFS时指定的目录</td></tr><tr><td>16</td><td>--where</td><td>从关系数据库导入数据时的查询条件</td></tr><tr><td>17</td><td>--z或--compress</td><td>允许压缩</td></tr><tr><td>18</td><td>--compression-codec</td><td>指定hadoop压缩编码类，默认为gzip(Use Hadoop codec default gzip)</td></tr><tr><td>19</td><td>--null-string <code>&lt;null-string&gt;</code></td><td>string类型的列如果null，替换为指定字符串</td></tr><tr><td>20</td><td>--null-non-string <code>&lt;null-string&gt;</code></td><td>非string类型的列如果null，替换为指定字符串</td></tr><tr><td>21</td><td>--check-column <code>&lt;col&gt;</code></td><td>作为增量导入判断的列名</td></tr><tr><td>22</td><td>--incremental <code>&lt;mode&gt;</code></td><td>mode：append或lastmodified</td></tr><tr><td>23</td><td>--last-value <code>&lt;value&gt;</code></td><td>指定某一个值，用于标记增量导入的位置</td></tr></tbody></table><h3 id="_5-2-6-命令-参数-export" tabindex="-1"><a class="header-anchor" href="#_5-2-6-命令-参数-export"><span><strong>5.2.6</strong> <strong>命令</strong>&amp;参数：export</span></a></h3><p>从HDFS（包括Hive和HBase）中奖数据导出到关系型数据库中。</p><p><strong>1)</strong> <strong>命令：</strong></p><p><strong>如：</strong></p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> export</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--export-dir </span><span style="color:#98C379;--shiki-dark:#98C379;">/user/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--input-fields-terminated-by </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;\\t&quot;</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--num-mappers </span><span style="color:#D19A66;--shiki-dark:#D19A66;">1</span></span></code></pre></div><p><strong>2)</strong> <strong>参数：</strong></p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--direct</td><td>利用数据库自带的导入导出工具，以便于提高效率</td></tr><tr><td>2</td><td>--export-dir <code>&lt;dir&gt;</code></td><td>存放数据的HDFS的源目录</td></tr><tr><td>3</td><td>-m或--num-mappers <code>&lt;n&gt;</code></td><td>启动N个map来并行导入数据，默认4个</td></tr><tr><td>4</td><td>--table <code>&lt;table-name&gt;</code></td><td>指定导出到哪个RDBMS中的表</td></tr><tr><td>5</td><td>--update-key <code>&lt;col-name&gt;</code></td><td>对某一列的字段进行更新操作</td></tr><tr><td>6</td><td>--update-mode <code>&lt;mode&gt;</code></td><td>updateonly allowinsert(默认)</td></tr><tr><td>7</td><td>--input-null-string <code>&lt;null-string&gt;</code></td><td>请参考import该类似参数说明</td></tr><tr><td>8</td><td>--input-null-non-string <code>&lt;null-string&gt;</code></td><td>请参考import该类似参数说明</td></tr><tr><td>9</td><td>--staging-table <code>&lt;staging-table-name&gt;</code></td><td>创建一张临时表，用于存放所有事务的结果，然后将所有事务结果一次性导入到目标表中，防止错误。</td></tr><tr><td>10</td><td>--clear-staging-table</td><td>如果第9个参数非空，则可以在导出操作执行前，清空临时事务结果表</td></tr></tbody></table><h3 id="_5-2-7-命令-参数-codegen" tabindex="-1"><a class="header-anchor" href="#_5-2-7-命令-参数-codegen"><span><strong>5.2.7</strong> <strong>命令</strong>&amp;参数：codegen</span></a></h3><p>将关系型数据库中的表映射为一个Java类，在该类中有各列对应的各个字段。</p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> codegen</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--bindir </span><span style="color:#98C379;--shiki-dark:#98C379;">/home/admin/Desktop/staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--class-name </span><span style="color:#98C379;--shiki-dark:#98C379;">Staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--fields-terminated-by </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;\\t&quot;</span></span></code></pre></div><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--bindir <code>&lt;dir&gt;</code></td><td>指定生成的Java文件、编译成的class文件及将生成文件打包为jar的文件输出路径</td></tr><tr><td>2</td><td>--class-name <code>&lt;name&gt;</code></td><td>设定生成的Java文件指定的名称</td></tr><tr><td>3</td><td>--outdir <code>&lt;dir&gt;</code></td><td>生成Java文件存放的路径</td></tr><tr><td>4</td><td>--package-name <code>&lt;name&gt;</code></td><td>包名，如com.z，就会生成com和z两级目录</td></tr><tr><td>5</td><td>--input-null-non-string <code>&lt;null-str&gt;</code></td><td>在生成的Java文件中，可以将null字符串或者不存在的字符串设置为想要设定的值（例如空字符串）</td></tr><tr><td>6</td><td>--input-null-string <code>&lt;null-str&gt;</code></td><td>将null字符串替换成想要替换的值（一般与5同时使用）</td></tr><tr><td>7</td><td>--map-column-java <code>&lt;arg&gt;</code></td><td>数据库字段在生成的Java文件中会映射成各种属性，且默认的数据类型与数据库类型保持对应关系。该参数可以改变默认类型，例如：--map-column-java id=long, name=String</td></tr><tr><td>8</td><td>--null-non-string <code>&lt;null-str&gt;</code></td><td>在生成Java文件时，可以将不存在或者null的字符串设置为其他值</td></tr><tr><td>9</td><td>--null-string <code>&lt;null-str&gt;</code></td><td>在生成Java文件时，将null字符串设置为其他值（一般与8同时使用）</td></tr><tr><td>10</td><td>--table <code>&lt;table-name&gt;</code></td><td>对应关系数据库中的表名，生成的Java文件中的各个属性与该表的各个字段一一对应</td></tr></tbody></table><h3 id="_5-2-8-命令-参数-create-hive-table" tabindex="-1"><a class="header-anchor" href="#_5-2-8-命令-参数-create-hive-table"><span><strong>5.2.8</strong> <strong>命令</strong>&amp;参数：create-hive-table</span></a></h3><p>生成与关系数据库表结构对应的hive表结构。</p><p><strong>命令：</strong></p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> create-hive-table</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--hive-table </span><span style="color:#98C379;--shiki-dark:#98C379;">hive_staff</span></span></code></pre></div><p><strong>参数：</strong></p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--hive-home <code>&lt;dir&gt;</code></td><td>Hive的安装目录，可以通过该参数覆盖掉默认的Hive目录</td></tr><tr><td>2</td><td>--hive-overwrite</td><td>覆盖掉在Hive表中已经存在的数据</td></tr><tr><td>3</td><td>--create-hive-table</td><td>默认是false，如果目标表已经存在了，那么创建任务会失败</td></tr><tr><td>4</td><td>--hive-table</td><td>后面接要创建的hive表</td></tr><tr><td>5</td><td>--table</td><td>指定关系数据库的表名</td></tr></tbody></table><h3 id="_5-2-9-命令-参数-eval" tabindex="-1"><a class="header-anchor" href="#_5-2-9-命令-参数-eval"><span><strong>5.2.9</strong> *<em>命令</em>&amp;***参数：eval</span></a></h3><p>可以快速的使用SQL语句对关系型数据库进行操作，经常用于在import数据之前，了解一下SQL语句是否正确，数据是否正常，并可以将结果显示在控制台。</p><p><strong>命令：</strong></p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> eval</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--query </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;SELECT * FROM staff&quot;</span></span></code></pre></div><p><strong>参数：</strong></p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--query或--e</td><td>后跟查询的SQL语句</td></tr></tbody></table><h3 id="_5-2-10-命令-参数-import-all-tables" tabindex="-1"><a class="header-anchor" href="#_5-2-10-命令-参数-import-all-tables"><span><strong>5.2.10</strong> <strong>命令</strong>&amp;参数：import-all-tables</span></a></h3><p>可以将RDBMS中的所有表导入到HDFS中，每一个表都对应一个HDFS目录</p><p><strong>命令：</strong></p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> import-all-tables</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--warehouse-dir </span><span style="color:#98C379;--shiki-dark:#98C379;">/all_tables</span></span></code></pre></div><p><strong>参数：</strong></p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--as-avrodatafile</td><td>这些参数的含义均和import对应的含义一致</td></tr><tr><td>2</td><td>--as-sequencefile</td><td></td></tr><tr><td>3</td><td>--as-textfile</td><td></td></tr><tr><td>4</td><td>--direct</td><td></td></tr><tr><td>5</td><td>--direct-split-size <code>&lt;n&gt;</code></td><td></td></tr><tr><td>6</td><td>--inline-lob-limit <code>&lt;n&gt;</code></td><td></td></tr><tr><td>7</td><td>--m或—num-mappers <code>&lt;n&gt;</code></td><td></td></tr><tr><td>8</td><td>--warehouse-dir <code>&lt;dir&gt;</code></td><td></td></tr><tr><td>9</td><td>-z或--compress</td><td></td></tr><tr><td>10</td><td>--compression-codec</td><td></td></tr></tbody></table><h3 id="_5-2-11-命令-参数-job" tabindex="-1"><a class="header-anchor" href="#_5-2-11-命令-参数-job"><span><strong>5.2.11</strong> <strong>命令</strong>&amp;参数：job</span></a></h3><p>用来生成一个sqoop任务，生成后不会立即执行，需要手动执行。</p><p><strong>命令：</strong></p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> job</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;"> --create</span><span style="color:#98C379;--shiki-dark:#98C379;"> myjob</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> --</span><span style="color:#98C379;--shiki-dark:#98C379;"> import-all-tables</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;"> --connect</span><span style="color:#98C379;--shiki-dark:#98C379;"> jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;"> --username</span><span style="color:#98C379;--shiki-dark:#98C379;"> root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;"> --password</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> 000000</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> job</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--list</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> job</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--exec </span><span style="color:#98C379;--shiki-dark:#98C379;">myjob</span></span></code></pre></div><p>尖叫提示：注意import-all-tables和它左边的--之间有一个空格</p><p>尖叫提示：如果需要连接metastore，则--meta-connect jdbc:hsqldb:hsql://linux01:16000/sqoop</p><p>参数：</p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--create <code>&lt;job-id&gt;</code></td><td>创建job参数</td></tr><tr><td>2</td><td>--delete <code>&lt;job-id&gt;</code></td><td>删除一个job</td></tr><tr><td>3</td><td>--exec <code>&lt;job-id&gt;</code></td><td>执行一个job</td></tr><tr><td>4</td><td>--help</td><td>显示job帮助</td></tr><tr><td>5</td><td>--list</td><td>显示job列表</td></tr><tr><td>6</td><td>--meta-connect <code>&lt;jdbc-uri&gt;</code></td><td>用来连接metastore服务</td></tr><tr><td>7</td><td>--show <code>&lt;job-id&gt;</code></td><td>显示一个job的信息</td></tr><tr><td>8</td><td>--verbose</td><td>打印命令运行时的详细信息</td></tr></tbody></table><p>尖叫提示：在执行一个job时，如果需要手动输入数据库密码，可以做如下优化</p><div class="language-xml" data-ext="xml" data-title="xml"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">\`&lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">property</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">	\`&lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">name</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`sqoop.metastore.client.record.password\`&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">name</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">	\`&lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">value</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`true\`&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">value</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">	\`&lt;</span><span style="color:#E06C75;--shiki-dark:#E06C75;">description</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`If true, allow saved passwords in the metastore.\`&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">description</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">\`&lt;/</span><span style="color:#E06C75;--shiki-dark:#E06C75;">property</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">&gt;\`</span></span></code></pre></div><h3 id="_5-2-12-命令-参数-list-databases" tabindex="-1"><a class="header-anchor" href="#_5-2-12-命令-参数-list-databases"><span><strong>5.2.12</strong> <strong>命令</strong>&amp;参数：list-databases</span></a></h3><p><strong>命令：</strong></p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> list-databases</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span></span></code></pre></div><p>**参数：**与公用参数一样</p><h3 id="_5-2-13-命令-参数-list-tables" tabindex="-1"><a class="header-anchor" href="#_5-2-13-命令-参数-list-tables"><span><strong>5.2.13</strong> <strong>命令</strong>&amp;参数：list-tables</span></a></h3><p><strong>命令：</strong></p><p>如：</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> list-tables</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span></span></code></pre></div><p>**参数：**与公用参数一样</p><h3 id="_5-2-14-命令-参数-merge" tabindex="-1"><a class="header-anchor" href="#_5-2-14-命令-参数-merge"><span><strong>5.2.14</strong> <strong>命令</strong>&amp;参数：merge</span></a></h3><p>将HDFS中不同目录下面的数据合并在一起并放入指定目录中</p><p>数据环境：</p><div class="language-txt" data-ext="txt" data-title="txt"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>new_staff</span></span>
<span class="line"><span>1       AAA     male</span></span>
<span class="line"><span>2       BBB     male</span></span>
<span class="line"><span>3       CCC     male</span></span>
<span class="line"><span>4       DDD     male</span></span>
<span class="line"><span>old_staff</span></span>
<span class="line"><span>1       AAA     female</span></span>
<span class="line"><span>2       CCC     female</span></span>
<span class="line"><span>3       BBB     female</span></span>
<span class="line"><span>6       DDD     female</span></span></code></pre></div><p>尖叫提示：上边数据的列之间的分隔符应该为\\t，行与行之间的分割符为\\n，如果直接复制，请检查之。</p><p><strong>命令：</strong></p><p>如：</p><div class="language-shell line-numbers-mode" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">创建JavaBean：</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> codegen</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--connect </span><span style="color:#98C379;--shiki-dark:#98C379;">jdbc:mysql://hadoop102:3306/company</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--username </span><span style="color:#98C379;--shiki-dark:#98C379;">root</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--password </span><span style="color:#D19A66;--shiki-dark:#D19A66;">000000</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--table </span><span style="color:#98C379;--shiki-dark:#98C379;">staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--bindir </span><span style="color:#98C379;--shiki-dark:#98C379;">/home/admin/Desktop/staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--class-name </span><span style="color:#98C379;--shiki-dark:#98C379;">Staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--fields-terminated-by </span><span style="color:#98C379;--shiki-dark:#98C379;">&quot;\\t&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">开始合并：</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> merge</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--new-data </span><span style="color:#98C379;--shiki-dark:#98C379;">/test/new/</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--onto </span><span style="color:#98C379;--shiki-dark:#98C379;">/test/old/</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--target-dir </span><span style="color:#98C379;--shiki-dark:#98C379;">/test/merged</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--jar-file </span><span style="color:#98C379;--shiki-dark:#98C379;">/home/admin/Desktop/staff/Staff.jar</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--class-name </span><span style="color:#98C379;--shiki-dark:#98C379;">Staff</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">--merge-key </span><span style="color:#98C379;--shiki-dark:#98C379;">id</span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-" data-ext="" data-title=""><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span>结果：</span></span>
<span class="line"><span>1	AAA	MALE</span></span>
<span class="line"><span>2	BBB	MALE</span></span>
<span class="line"><span>3	CCC	MALE</span></span>
<span class="line"><span>4	DDD	MALE</span></span>
<span class="line"><span>6	DDD	FEMALE</span></span></code></pre></div><p>参数：</p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--new-data <code>&lt;path&gt;</code></td><td>HDFS 待合并的数据目录，合并后在新的数据集中保留</td></tr><tr><td>2</td><td>--onto <code>&lt;path&gt;</code></td><td>HDFS合并后，重复的部分在新的数据集中被覆盖</td></tr><tr><td>3</td><td>--merge-key <code>&lt;col&gt;</code></td><td>合并键，一般是主键ID</td></tr><tr><td>4</td><td>--jar-file <code>&lt;file&gt;</code></td><td>合并时引入的jar包，该jar包是通过Codegen工具生成的jar包</td></tr><tr><td>5</td><td>--class-name <code>&lt;class&gt;</code></td><td>对应的表名或对象名，该class类是包含在jar包中的</td></tr><tr><td>6</td><td>--target-dir <code>&lt;path&gt;</code></td><td>合并后的数据在HDFS里存放的目录</td></tr></tbody></table><h3 id="_5-2-15-命令-参数-metastore" tabindex="-1"><a class="header-anchor" href="#_5-2-15-命令-参数-metastore"><span><strong>5.2.15</strong> <strong>命令</strong>&amp;参数：metastore</span></a></h3><p>记录了Sqoop job的元数据信息，如果不启动该服务，那么默认job元数据的存储目录为~/.sqoop，可在sqoop-site.xml中修改。</p><p><strong>命令：</strong></p><p>如：启动sqoop的metastore服务</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">$</span><span style="color:#98C379;--shiki-dark:#98C379;"> bin/sqoop</span><span style="color:#98C379;--shiki-dark:#98C379;"> metastore</span></span></code></pre></div><p><strong>参数：</strong></p><table><thead><tr><th><strong>序号</strong></th><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>1</td><td>--shutdown</td><td>关闭metastore</td></tr></tbody></table>`,101)]))}const i=t(e,[["render",r],["__file","Sqoop一些常用命令及参数.html.vue"]]),p=JSON.parse('{"path":"/posts/BigData/04_%E6%8E%A5%E5%85%A5%E5%B1%82/Sqoop%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%8A%E5%8F%82%E6%95%B0.html","title":"Sqoop一些常用命令及参数","lang":"zh-CN","frontmatter":{"description":"Sqoop一些常用命令及参数 5.1 常用命令列举 5.2 命令&参数详解 刚才列举了一些Sqoop的常用命令，对于不同的命令，有不同的参数，让我们来一一列举说明。 首先来我们来介绍一下公用的参数，所谓公用参数，就是大多数命令都支持的参数。 5.2.1 公用参数：数据库连接 5.2.2 **公用参数：**import 5.2.3 **公用参数：**ex...","watermark":true,"head":[["meta",{"property":"og:url","content":"https://springg.us.kg/posts/BigData/04_%E6%8E%A5%E5%85%A5%E5%B1%82/Sqoop%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%8A%E5%8F%82%E6%95%B0.html"}],["meta",{"property":"og:site_name","content":"mrjason’s Blog"}],["meta",{"property":"og:title","content":"Sqoop一些常用命令及参数"}],["meta",{"property":"og:description","content":"Sqoop一些常用命令及参数 5.1 常用命令列举 5.2 命令&参数详解 刚才列举了一些Sqoop的常用命令，对于不同的命令，有不同的参数，让我们来一一列举说明。 首先来我们来介绍一下公用的参数，所谓公用参数，就是大多数命令都支持的参数。 5.2.1 公用参数：数据库连接 5.2.2 **公用参数：**import 5.2.3 **公用参数：**ex..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-28T01:58:08.000Z"}],["meta",{"property":"article:author","content":"MrJason"}],["meta",{"property":"article:modified_time","content":"2024-10-28T01:58:08.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Sqoop一些常用命令及参数\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-10-28T01:58:08.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"MrJason\\",\\"url\\":\\"https://springg.us.kg\\"}]}"]]},"headers":[{"level":2,"title":"5.1 常用命令列举","slug":"_5-1-常用命令列举","link":"#_5-1-常用命令列举","children":[]},{"level":2,"title":"5.2 命令&参数详解","slug":"_5-2-命令-参数详解","link":"#_5-2-命令-参数详解","children":[{"level":3,"title":"5.2.1 公用参数：数据库连接","slug":"_5-2-1-公用参数-数据库连接","link":"#_5-2-1-公用参数-数据库连接","children":[]},{"level":3,"title":"5.2.2 **公用参数：**import","slug":"_5-2-2-公用参数-import","link":"#_5-2-2-公用参数-import","children":[]},{"level":3,"title":"5.2.3 **公用参数：**export","slug":"_5-2-3-公用参数-export","link":"#_5-2-3-公用参数-export","children":[]},{"level":3,"title":"5.2.4 **公用参数：**hive","slug":"_5-2-4-公用参数-hive","link":"#_5-2-4-公用参数-hive","children":[]},{"level":3,"title":"5.2.5 命令&参数：import","slug":"_5-2-5-命令-参数-import","link":"#_5-2-5-命令-参数-import","children":[]},{"level":3,"title":"5.2.6 命令&参数：export","slug":"_5-2-6-命令-参数-export","link":"#_5-2-6-命令-参数-export","children":[]},{"level":3,"title":"5.2.7 命令&参数：codegen","slug":"_5-2-7-命令-参数-codegen","link":"#_5-2-7-命令-参数-codegen","children":[]},{"level":3,"title":"5.2.8 命令&参数：create-hive-table","slug":"_5-2-8-命令-参数-create-hive-table","link":"#_5-2-8-命令-参数-create-hive-table","children":[]},{"level":3,"title":"5.2.9 *命令&***参数：eval","slug":"_5-2-9-命令-参数-eval","link":"#_5-2-9-命令-参数-eval","children":[]},{"level":3,"title":"5.2.10 命令&参数：import-all-tables","slug":"_5-2-10-命令-参数-import-all-tables","link":"#_5-2-10-命令-参数-import-all-tables","children":[]},{"level":3,"title":"5.2.11 命令&参数：job","slug":"_5-2-11-命令-参数-job","link":"#_5-2-11-命令-参数-job","children":[]},{"level":3,"title":"5.2.12 命令&参数：list-databases","slug":"_5-2-12-命令-参数-list-databases","link":"#_5-2-12-命令-参数-list-databases","children":[]},{"level":3,"title":"5.2.13 命令&参数：list-tables","slug":"_5-2-13-命令-参数-list-tables","link":"#_5-2-13-命令-参数-list-tables","children":[]},{"level":3,"title":"5.2.14 命令&参数：merge","slug":"_5-2-14-命令-参数-merge","link":"#_5-2-14-命令-参数-merge","children":[]},{"level":3,"title":"5.2.15 命令&参数：metastore","slug":"_5-2-15-命令-参数-metastore","link":"#_5-2-15-命令-参数-metastore","children":[]}]}],"git":{"createdTime":1730080688000,"updatedTime":1730080688000,"contributors":[{"name":"MrJason","email":"845886914@qq.com","commits":1}]},"readingTime":{"minutes":11.97,"words":3592},"filePathRelative":"posts/BigData/04_接入层/Sqoop一些常用命令及参数.md","localizedDate":"2024年10月28日","excerpt":"\\n<h2><strong>5.1</strong> <strong>常用命令列举</strong></h2>\\n<table>\\n<thead>\\n<tr>\\n<th><strong>序号</strong></th>\\n<th><strong>命令</strong></th>\\n<th><strong>类</strong></th>\\n<th><strong>说明</strong></th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>1</td>\\n<td>import</td>\\n<td>ImportTool</td>\\n<td>将数据导入到集群</td>\\n</tr>\\n<tr>\\n<td>2</td>\\n<td>export</td>\\n<td>ExportTool</td>\\n<td>将集群数据导出</td>\\n</tr>\\n<tr>\\n<td>3</td>\\n<td>codegen</td>\\n<td>CodeGenTool</td>\\n<td>获取数据库中某张表数据生成Java并打包Jar</td>\\n</tr>\\n<tr>\\n<td>4</td>\\n<td>create-hive-table</td>\\n<td>CreateHiveTableTool</td>\\n<td>创建Hive表</td>\\n</tr>\\n<tr>\\n<td>5</td>\\n<td>eval</td>\\n<td>EvalSqlTool</td>\\n<td>查看SQL执行结果</td>\\n</tr>\\n<tr>\\n<td>6</td>\\n<td>import-all-tables</td>\\n<td>ImportAllTablesTool</td>\\n<td>导入某个数据库下所有表到HDFS中</td>\\n</tr>\\n<tr>\\n<td>7</td>\\n<td>job</td>\\n<td>JobTool</td>\\n<td>用来生成一个sqoop的任务，生成后，该任务并不执行，除非使用命令执行该任务。</td>\\n</tr>\\n<tr>\\n<td>8</td>\\n<td>list-databases</td>\\n<td>ListDatabasesTool</td>\\n<td>列出所有数据库名</td>\\n</tr>\\n<tr>\\n<td>9</td>\\n<td>list-tables</td>\\n<td>ListTablesTool</td>\\n<td>列出某个数据库下所有表</td>\\n</tr>\\n<tr>\\n<td>10</td>\\n<td>merge</td>\\n<td>MergeTool</td>\\n<td>将HDFS中不同目录下面的数据合在一起，并存放在指定的目录中</td>\\n</tr>\\n<tr>\\n<td>11</td>\\n<td>metastore</td>\\n<td>MetastoreTool</td>\\n<td>记录sqoop job的元数据信息，如果不启动metastore实例，则默认的元数据存储目录为：~/.sqoop，如果要更改存储目录，可以在配置文件sqoop-site.xml中进行更改。</td>\\n</tr>\\n<tr>\\n<td>12</td>\\n<td>help</td>\\n<td>HelpTool</td>\\n<td>打印sqoop帮助信息</td>\\n</tr>\\n<tr>\\n<td>13</td>\\n<td>version</td>\\n<td>VersionTool</td>\\n<td>打印sqoop版本信息</td>\\n</tr>\\n</tbody>\\n</table>","autoDesc":true}');export{i as comp,p as data};
